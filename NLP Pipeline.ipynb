{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21335bb-827d-48d8-9163-c8a74a3662f1",
   "metadata": {},
   "source": [
    "# nlp 12-09-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4450965a-08e3-4467-a2c6-01935dec1564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is neema\n"
     ]
    }
   ],
   "source": [
    "name = \"neema\"\n",
    "print(f\"my name is {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f16312d-c309-4887-925f-4fe704689726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is 'neema'\n"
     ]
    }
   ],
   "source": [
    "print(f\"my name is 'neema'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71d98ba",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3830d038-b804-448e-9c0b-ae07103f7f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is 'neema'\n"
     ]
    }
   ],
   "source": [
    "print(f\"my name is {name!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49cc1b6-c95e-49af-887b-b7a1769033ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my name is 'neema'\n"
     ]
    }
   ],
   "source": [
    "print(f\"my name is '{name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc18e821-4cdd-4133-b068-f9fcf10bf4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 address is to 123 main street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d70fad8-4838-4276-a0c8-fbe60f89c292",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'a':123,'b':456}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "873eae20-1521-48bc-ae58-2d1f86010cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "address is to 123 main street\n"
     ]
    }
   ],
   "source": [
    "print(f\"address is to {a['a']} main street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72509b68-86cc-456d-84bf-e385135df202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author     topic      pages\n",
      "a          phy         67\n",
      "b          chem       1062\n",
      "c          math       459\n"
     ]
    }
   ],
   "source": [
    "# 3) question\n",
    "\n",
    "# print this using f string\n",
    "\n",
    "# author,topic,pages\n",
    "# a,phy,67\n",
    "# b,chem,1062\n",
    "# c,math,459\n",
    "\n",
    "\n",
    " \n",
    "library = [(\"author\",\"topic\",\"pages\"),(\"a\",\"phy\",67),(\"b\",\"chem\",1062),(\"c\",\"math\",459)]\n",
    "for book in library:\n",
    "    print(f\"{book[0]:{10}} {book[1]:{10}} {book[2]:{3}}\")\n",
    "\n",
    "# {book[0]:{10}} ->  ALSO {book[0]:10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c36cc92-bb7c-4b6d-8b07-9a8e2d976f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author     topic      .....pages\n",
      "a          phy        ........67\n",
      "b          chem       ......1062\n",
      "c          math       .......459\n"
     ]
    }
   ],
   "source": [
    "for book in library:\n",
    "    print(f\"{book[0]:{10}} {book[1]:{10}} {book[2]:.>{10}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee1f7e1d-8d06-43c1-b471-3cc055b242e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author     topic      #####pages\n",
      "a          phy        ########67\n",
      "b          chem       ######1062\n",
      "c          math       #######459\n"
     ]
    }
   ],
   "source": [
    "for book in library:\n",
    "    print(f\"{book[0]:{10}} {book[1]:{10}} {book[2]:#>{10}}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2179f48-b478-4d88-aa62-2624c25fef30",
   "metadata": {},
   "source": [
    "# 13 9 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff01dc7-7b45-4620-99e6-ff57cb5ca736",
   "metadata": {},
   "source": [
    "# FIle Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc5131bd-ca37-4e8d-a0ea-d0751c963575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 11, 8, 15, 43, 8, 748910)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing date and time\n",
    "#<--------------------------->\n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00c99a4d-19bb-4a2c-a9b1-d530b7c30d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# code 1) write\n",
    "%%writefile test.txt\n",
    "Hi1\n",
    "Hi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88083a7-ca2e-4510-96d5-fbfce0a99e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi3\\nHi4'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 2) read\n",
    "my_file = open('test.txt')\n",
    "my_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "51735acd-e17c-4a2f-a227-3bb44e3ef344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72ffa411-a053-4ac5-982b-89d4c96474c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 3) ab iska cursor 3rd line pe chla gya,\n",
    "# and 3rd line has not any content so it shows the blank output\n",
    "my_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6de15afc-f0ab-4a87-83c8-240ce4d8228c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 4) we can use seek to cursor ko wapas starting se means 0 index se read krne ke liye\n",
    "my_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e0de8bef-bf94-43c0-b24e-4d67d5e46a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi3\\nHi4'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 4.1)\n",
    "my_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "16a9b1bf-6588-4845-86d6-e8356238221d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 5) readlines\n",
    "my_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bbea767c-b72b-4596-801b-1622f3a4b448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 6.1)\n",
    "my_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "6d44b232-b5a2-44aa-b2f4-5d3e6bb270e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code 6.2)\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eaf3a086-7294-484d-8639-2ecdf9cd0812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_file = open('test.txt', 'w+')\n",
    "my_file.write(\"Hi3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7bf5f6d5-84cc-46c4-b7a6-ddd26db21a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 6.3)\n",
    "my_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a834ec33-73cf-4a97-b764-5329ba74bbc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi3'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 6.4\n",
    "my_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7f9ec76e-9343-4241-bb6e-a4841a6b1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write mode me open krke hm write krenge then it will overright.\n",
    "# means it will delete the previous content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9ec68360-054f-4658-9e2c-0eee9ed55796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code 7)\n",
    "\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "aefb2257-9772-4e83-9a1c-29b67b784984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 8.1) open file in append mode\n",
    "\n",
    "my_file = open('test.txt', 'a+')\n",
    "my_file.write(\"\\nHi4\")\n",
    "\n",
    "# output is 3 means 3 elements/word in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a867d801-b810-4757-997d-238845ef6689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 8.2\n",
    "my_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "be520922-9281-498d-b5bc-df83a050aa17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi3\\nHi4'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 8.3\n",
    "my_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f8b7d127-40b8-49ab-bdfe-3619c175037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 8.4\n",
    "my_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "78421230-f1d2-49c7-b326-7167533a0b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi3\n",
      "Hi4\n"
     ]
    }
   ],
   "source": [
    "# code 8.5\n",
    "print(my_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1f8c0e8e-cfc2-4d62-90fc-4e274b307581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seek if continuous 2 times read krenge to blank dikhayega so we use seek.\n",
    "# after every 2 read code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a8c635d4-4ec1-4d42-881c-ca063ad184fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mycodes\n",
    "#<-------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "258ad013-6f6b-4bff-ae58-c68674d48d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code1.1) write(\"\")\n",
    "f3= open('myfile5.txt','w')\n",
    "f3.write(\"12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4aea82ef-b8c1-4476-bef7-64f83065f1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 1.2)\n",
    "f3= open('myfile5.txt','r')\n",
    "f3.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "38a43fd4-eeb3-459e-94da-1a76b7463032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 1.3)\n",
    "f3= open('myfile5.txt','a')\n",
    "f3.write(\"34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "584dd45a-945e-4a27-9df3-677011c92f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 1.4)\n",
    "f3= open('myfile5.txt','r')\n",
    "f3.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009f870-28b4-49ee-b0b5-89ca38e2167c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "a645da00-0cb7-49cc-ad55-09a793f54096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# code 9)\n",
    "with open ('test.txt','r') as text:\n",
    "    first_line = text.readlines()[0]\n",
    "print(first_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b400a475-8ecd-45d9-a650-f151849f7c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi3\n",
      "\n",
      "Hi4\n"
     ]
    }
   ],
   "source": [
    "# code 10) to read all line use loop\n",
    "with open('test.txt','r') as txt:\n",
    "    for line in txt:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2311bcc5-c6f5-4422-a67c-a59da6960411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended code\n",
    "# with open('myfile.txt', 'r') as f:\n",
    "#     doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd73ea81-181f-416f-a15d-8a79f3480888",
   "metadata": {},
   "source": [
    "# Read Pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "375bef3c-1db7-4a50-8d18-396524092635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (3.0.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Acer\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Acer\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\Acer\\anaconda3\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# code 1) install PyPDF2\n",
    "\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "855b6637-c419-466a-aa2b-f02e81115cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code 2) importing PyPDF2\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fde0b8-1d6e-4f7e-90b6-6150bfb6eed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3579be63-6e64-4645-9b1d-ded0c7555a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='C:\\\\Users\\\\Acer\\\\OneDrive\\\\Desktop\\\\WPS PDF.lnk'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 3) \n",
    "\n",
    "# rb means read binary file\n",
    "pdf_path = r'C:\\Users\\Acer\\OneDrive\\Desktop\\WPS PDF.lnk'\n",
    "f = open(pdf_path, 'rb')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee6ce79e-9d72-41f6-9073-8ac8894d17cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "PdfReadError",
     "evalue": "EOF marker not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPdfReadError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# code 4)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m reader \u001b[38;5;241m=\u001b[39m PyPDF2\u001b[38;5;241m.\u001b[39mPdfReader(f)\n\u001b[0;32m      4\u001b[0m reader\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_reader.py:319\u001b[0m, in \u001b[0;36mPdfReader.__init__\u001b[1;34m(self, stream, strict, password)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(stream, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh:\n\u001b[0;32m    318\u001b[0m         stream \u001b[38;5;241m=\u001b[39m BytesIO(fh\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m--> 319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(stream)\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream \u001b[38;5;241m=\u001b[39m stream\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_override_encryption \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_reader.py:1415\u001b[0m, in \u001b[0;36mPdfReader.read\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream: StreamType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_basic_validation(stream)\n\u001b[1;32m-> 1415\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_eof_marker(stream)\n\u001b[0;32m   1416\u001b[0m     startxref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_startxref_pos(stream)\n\u001b[0;32m   1418\u001b[0m     \u001b[38;5;66;03m# check and eventually correct the startxref only in not strict\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_reader.py:1471\u001b[0m, in \u001b[0;36mPdfReader._find_eof_marker\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m line[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mEOF\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mtell() \u001b[38;5;241m<\u001b[39m last_mb:\n\u001b[1;32m-> 1471\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m PdfReadError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEOF marker not found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1472\u001b[0m     line \u001b[38;5;241m=\u001b[39m read_previous_line(stream)\n",
      "\u001b[1;31mPdfReadError\u001b[0m: EOF marker not found"
     ]
    }
   ],
   "source": [
    "# code 4)\n",
    "\n",
    "reader = PyPDF2.PdfReader(f)\n",
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d58daab-d5db-4fd0-a802-54800cd6b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing no. of pages\n",
    "len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fdd0a-86be-4abe-91e6-6144b7d565ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_one = reader.pages[0] # it read 1st page becoz indexing is zero\n",
    "page_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f46bd16-8bba-4f9d-b669-eb64cecc7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_one_text = page_one.extract_text()\n",
    "page_one_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f1317c-b235-4800-8572-c65e8cb53e6a",
   "metadata": {},
   "source": [
    "# 17 sep 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aff434-32a6-4713-befe-d7bf52c981ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revise (what we have learnt)\n",
    "#<--------------------------------->\n",
    "# NLP Introduction\n",
    "# NLP Pipeline\n",
    "# working with text files\n",
    "# working with PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96b9357-ee41-4522-981f-73081c6978f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how to copy path\n",
    "\n",
    "# 1. direct copy as path\n",
    "# 2. properties, security, object -> here complete path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828956f-554a-4e1d-885d-f1de3b37c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rb -> read binary (used to read pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee8a186-7543-4656-b83f-b4c668474c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_one_text = page_one.extract_text()\n",
    "page_one_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931963c5-08eb-42b4-827a-98af66572c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(pdf_path,'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618fe55e-3cd8-4406-aa62-1c37d613ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text=[]\n",
    "\n",
    "pdf_reader = PyPDF2.PdfReader(f)\n",
    "\n",
    "for p in range(len(pdf_reader.pages)):\n",
    "    \n",
    "    page = pdf_reader.pages[p]\n",
    "    pdf_text.append(page.extract_text())\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61a5d29-d772-4f50-a320-77f8c6b82762",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b125cd3-168c-43fe-8965-17811568f507",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "1babff23-525f-465e-a586-6b688eaffddb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pdf_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# loop in pdf pages\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m pdf_text:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(page)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pdf_text' is not defined"
     ]
    }
   ],
   "source": [
    "# loop in pdf pages\n",
    "for page in pdf_text:\n",
    "    print(page)\n",
    "    print('\\n')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "3d36c344-8bc3-4a36-b46c-2647dcd18071",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Downloads\\\\nlppdf (1).pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[185], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Accessing the first page\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(pdf_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m pdf_reader \u001b[38;5;241m=\u001b[39m PyPDF2\u001b[38;5;241m.\u001b[39mPdfReader(f)\n\u001b[0;32m      4\u001b[0m first_page \u001b[38;5;241m=\u001b[39m pdf_reader\u001b[38;5;241m.\u001b[39mpages[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Acer\\\\Downloads\\\\nlppdf (1).pdf'"
     ]
    }
   ],
   "source": [
    "# Accessing the first page\n",
    "f = open(pdf_path, 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(f)\n",
    "first_page = pdf_reader.pages[0]\n",
    "first_page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995133e-cd7a-4dfa-876e-ffc9ebbd9998",
   "metadata": {},
   "source": [
    "# 18 sep 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c2d5ffb-6213-460c-8720-4c109a912070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0054d5be-62b9-499c-a342-b91a56815dce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m first_page \u001b[38;5;241m=\u001b[39m pdf_reader\u001b[38;5;241m.\u001b[39mpages[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m      5\u001b[0m pdf_writer \u001b[38;5;241m=\u001b[39m PyPDF2\u001b[38;5;241m.\u001b[39mPdfWriter()\n\u001b[1;32m----> 6\u001b[0m pdf_writer\u001b[38;5;241m.\u001b[39madd_page(first_page)\n\u001b[0;32m      7\u001b[0m pdf_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNew_Doc.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m pdf_writer\u001b[38;5;241m.\u001b[39mwrite(pdf_output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_writer.py:321\u001b[0m, in \u001b[0;36mPdfWriter.add_page\u001b[1;34m(self, page, excluded_keys)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_page\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    308\u001b[0m     page: PageObject,\n\u001b[0;32m    309\u001b[0m     excluded_keys: Iterable[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m (),\n\u001b[0;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PageObject:\n\u001b[0;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;124;03m    Add a page to this PDF file.\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    Recommended for advanced usage including the adequate excluded_keys\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03m        an instance of :class:`PageObject<PyPDF2._page.PageObject>`\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_page(page, \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m.\u001b[39mappend, excluded_keys)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_writer.py:258\u001b[0m, in \u001b[0;36mPdfWriter._add_page\u001b[1;34m(self, page, action, excluded_keys)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add_page\u001b[39m(\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    254\u001b[0m     page: PageObject,\n\u001b[0;32m    255\u001b[0m     action: Callable[[Any, IndirectObject], \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[0;32m    256\u001b[0m     excluded_keys: Iterable[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m (),\n\u001b[0;32m    257\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PageObject:\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m cast(\u001b[38;5;28mstr\u001b[39m, page[PA\u001b[38;5;241m.\u001b[39mTYPE]) \u001b[38;5;241m==\u001b[39m CO\u001b[38;5;241m.\u001b[39mPAGE\n\u001b[0;32m    259\u001b[0m     page_org \u001b[38;5;241m=\u001b[39m page\n\u001b[0;32m    260\u001b[0m     excluded_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(excluded_keys)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PyPDF2\\_page.py:2071\u001b[0m, in \u001b[0;36m_VirtualList.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m   2069\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(indices\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__len__\u001b[39m, \u001b[38;5;28;01mlambda\u001b[39;00m idx: \u001b[38;5;28mself\u001b[39m[indices[idx]])  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m-> 2071\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence indices must be integers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2072\u001b[0m len_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   2073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2074\u001b[0m     \u001b[38;5;66;03m# support negative indexes\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: sequence indices must be integers"
     ]
    }
   ],
   "source": [
    "pdf_path = r'C:\\Users\\Acer\\Downloads\\DATA SCIENCE TASK.pdf'\n",
    "f = open(pdf_path,'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(f)\n",
    "first_page = pdf_reader.pages[0]\n",
    "pdf_writer = PyPDF2.PdfWriter()\n",
    "pdf_writer.add_page(first_page)\n",
    "pdf_output = open(\"New_Doc.pdf\",\"wb\")\n",
    "pdf_writer.write(pdf_output)\n",
    "pdf_output.close()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64d5068-e633-43ae-85ff-fd1789a2ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('New_Doc.pdf','rb')\n",
    "pdf_reader = PyPDF2.PdfReader(f)\n",
    "len(pdf_reader.pages)\n",
    "page_one = pdf_reader.pages[0]\n",
    "page_one_text = page_one.extract_text()\n",
    "page_one_text\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a5f9e-4783-469c-9c9b-c5e808d211eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f64f3fee-1604-4c64-81ba-762a6757af7e",
   "metadata": {},
   "source": [
    "# working with regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "cdd8f608-bf9a-417b-b76a-9d711a136290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(12, 17), match='phone'>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The agent's phone number is 408-555-1234. Call soon!\"\n",
    "'phone' in text\n",
    "\n",
    "import re\n",
    "pattern = 'phone'\n",
    "re.search(pattern,text)\n",
    "\n",
    "\n",
    "# directly hm pattern ke jhap phone ko bhi likh skte hai in quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fd2503b9-5c79-45c2-b843-baed4d875480",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"NOT IN TEXT\"\n",
    "re.search(pattern,text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "e08841a3-808a-456d-b139-7d9471d579d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(12, 17), match='phone'>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = 'phone'\n",
    "match = re.search(pattern,text)\n",
    "match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "038c500a-c547-4b23-8b8a-367e71255464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 17)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d0d45ee9-efa9-4d62-bcbd-068de1b7fe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "90283e79-758d-44c3-bccf-dce65676fb98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaac7c4-8b2d-4775-adad-6b9d8c3b9bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "b45332dd-3489-449e-bdfb-b8cd01a69ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 8)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"my phone is a new phone\"\n",
    "match = re.search(\"phone\",text)\n",
    "match.span()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "379ea118-46f6-4c54-82af-b425c031ab7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['phone', 'phone']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = re.findall(\"phone\",text)\n",
    "matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "aa740980-44f7-4f12-bd8a-0f5bc9cfd0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fb8734f1-20c5-4c67-946d-9d5141a355b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n",
      "(18, 23)\n"
     ]
    }
   ],
   "source": [
    "# To get actual matches\n",
    "for match in re.finditer(\"phone\",text):\n",
    "    print(match.span())\n",
    "\n",
    "# //finditer give all the matching value index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ea486f-bddf-4bb3-a0f3-71cad5e3457a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7eb3ecdc-74dd-4007-af54-3f6c5dbceb85",
   "metadata": {},
   "source": [
    "# Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "39e7508a-11f6-45b2-b915-07b21482c8a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 35), match='408-555-1234'>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 1) search\n",
    "#<----------------------------------->\n",
    "\n",
    "# pattern means identifiers\n",
    "\n",
    "import re\n",
    "text = \"My telephone number is 408-555-1234\"\n",
    "phone = re.search(r'\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d',text)\n",
    "phone\n",
    "\n",
    "# span=(23, 35) index start,end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8689a063-0d83-4cc7-93f4-ee9fd61e0e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408-555-1234'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 2) extracting only number\n",
    "#<---------------------------------->\n",
    "\n",
    "phone.group()\n",
    "\n",
    "# .group gives the only number\n",
    "\n",
    "# phone gives the object,span, and match everything\n",
    "# but phone.group() gives the only phone number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f5ebf-6b5d-4efb-8dcf-f697aba227cf",
   "metadata": {},
   "source": [
    "## Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a7775519-e6fa-43f9-aec9-215bbea3ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups means \\d\\d\\d isko hmne group kr diya -> \\d{3} isme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "e4198204-2d24-4470-b87b-c720b7725466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 35), match='408-555-1234'>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 4.1) remove repeatation of \\d                  method1\n",
    "#<------------------------------------>\n",
    "\n",
    "phone_pattern = re.compile(r'(\\d{3})-(\\d{3})-(\\d{4})')\n",
    "results = re.search(phone_pattern,text)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3e68d39b-7f6c-4a1c-aee8-4ca63a5e88dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 35), match='408-555-1234'>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 4.2) also without compile                      method 2\n",
    "#<---------------------------------->\n",
    "\n",
    "phone_pattern = r'(\\d{3})-(\\d{3})-(\\d{4})'\n",
    "results = re.search(phone_pattern,text)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6d51e957-0fef-4488-a6a2-0d67e508aa93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 35), match='408-555-1234'>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 4.3) also without r   recommended            method 3               \n",
    "#<-------------------------------->\n",
    "\n",
    "phone_pattern = '(\\d{3})-(\\d{3})-(\\d{4})'\n",
    "results = re.search(phone_pattern,text)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "56c0816c-f2f6-4372-a459-12a920f68bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(23, 35), match='408-555-1234'>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 4.4) method 4   recommended\n",
    "#<----------------->\n",
    " \n",
    "results = re.search(r'(\\d{3})-(\\d{3})-(\\d{4})',text)\n",
    "results\n",
    "\n",
    "# r ke bina bhi ho jayega."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117d5ab-f3b2-44c0-8cfc-00aee40f4e49",
   "metadata": {},
   "source": [
    "# The entire result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "4119b931-2300-463c-89b8-5744c11d1cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408-555-1234'"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code 5)\n",
    "results.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "1cb16a58-053e-47cd-8493-b845276d2162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'408'"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "results.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "df1182a3-a06f-4e49-9b56-ceedbcbc0bbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'555'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "fa39bdae-5966-4d7b-bc84-8505944fe931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e7dc1d10-1843-4679-902c-393f80b57e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.group(4)\n",
    "# IndexError: no such group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024c1fc-ccff-4861-bffe-44a9fd77b07f",
   "metadata": {},
   "source": [
    "# Additional REGEX Syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b8fe2-fd7a-4072-88e3-e36d43a565ca",
   "metadata": {},
   "source": [
    "## OR Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "3abb3530-b302-4147-b11b-78b019440bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search(r\"man|woman\",\"This man was here.\")\n",
    "\n",
    "span=(5, 8) # 8 excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b4fc9f42-6895-4dba-b4b6-a4f7e4389f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(5, 10), match='woman'>"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search(r\"man|woman\",\"This woman was here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "62c544a6-3372-4978-9629-201bf3542098",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Wildcard Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d72ec1f2-6cfe-4159-b5ec-ec72d58b5067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'hat', 'sat']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\".at\",\"The cat in the hat sat here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "76a1c557-7dd6-4433-b1c8-a44c8d4a52e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat', 'lat']"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\".at\",\"The bat went splat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "23db4de7-8b1d-40cf-9b9b-ce75584d0668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' cat', ' hat', ' sat']"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"..at\",\"The cat in the hat sat here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "4e940775-bf4a-4b0a-a52a-4cd01f553a37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e cat', 'e hat', '  sat']"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r\"...at\",\"The cat in the hat  sat here.\")\n",
    "\n",
    "# hat and sat dono me at hai so the code is consfusing.\n",
    "# so I use space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34eb26b-531c-4ec0-919b-45abf97ba2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "1fb5dd0f-a4c5-49c6-aa77-ce59e17ed1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One or more non-whitespace that ends with 'at'\n",
    "re.findall(r'S+at',\"The cat in the hat sat here.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "698b04fb-e229-4e75-91bb-31c7f5eec16a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2']"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Start With and ends With\n",
    "re.findall(r'\\d$', 'This ends with a number 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "d8ce2ab7-7014-4dec-8236-85a6664f2880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1']"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with a number\n",
    "re.findall(r'^\\d','1 is the loneliest number.')          #   cap sign and digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "4800601c-cd26-4efb-be54-8fdc84f4acfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mycode\n",
    "re.findall(r'^\\d',' is the 1 loneliest number.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "8edf970d-1f95-4c8c-91e8-df65710c600f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# understanding code\n",
    "re.findall(r'^\\d$','1 is the loneliest number 2.')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f7458-d136-46bb-9f41-0dca4e55b1fd",
   "metadata": {},
   "source": [
    "## Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d06a8163-4a0a-460c-9e21-c7ec5bb06738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t',\n",
       " 'h',\n",
       " 'e',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " 'a',\n",
       " 'r',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 'n',\n",
       " 'u',\n",
       " 'm',\n",
       " 'b',\n",
       " 'e',\n",
       " 'r',\n",
       " ' ',\n",
       " ' ',\n",
       " 'i',\n",
       " 'n',\n",
       " 's',\n",
       " 'i',\n",
       " 'd',\n",
       " 'e',\n",
       " ' ',\n",
       " ' ',\n",
       " 't',\n",
       " 'h',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 's',\n",
       " 'e',\n",
       " 'n',\n",
       " 't',\n",
       " 'e',\n",
       " 'n',\n",
       " 'c',\n",
       " 'e',\n",
       " '.']"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# startwidth = ^ cap\n",
    "# endwidth = $ dollar\n",
    "\n",
    "phrase = \"there are 3 number 34 inside 5 this sentence.\"\n",
    "re.findall(r'[^\\d]',phrase)  \n",
    "\n",
    "# it gives the output in characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5d80eb36-9963-4c93-a315-325b6722f733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['there are ', ' number ', ' inside ', ' this sentence.']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[^\\d]+',phrase) # exclude numbers\n",
    "\n",
    "# plus + sign give the output in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7fc53412-becc-4e89-9422-a38f10bc4ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'string',\n",
       " 'But',\n",
       " 'is',\n",
       " 'has',\n",
       " 'punctuation',\n",
       " 'How',\n",
       " 'can',\n",
       " 'we',\n",
       " 'remove',\n",
       " 'it']"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrase = 'This is a string! But is has punctuation. How can we remove it?'\n",
    "re.findall('[^!.? ]+',test_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "21850d63-a9be-4b7f-aa7d-33f42364f193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a string', ' But is has punctuation', ' How can we remove it']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrase = 'This is a string! But is has punctuation. How can we remove it?'\n",
    "re.findall('[^!.?]+',test_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "43876b4c-fa52-48c3-8b70-08339bf89a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!', '.', '?']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrase = 'This is a string! But is has punctuation. How can we remove it?'\n",
    "re.findall('[!.?$]+',test_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371c26c-fbd2-4960-9197-a85b439dfc86",
   "metadata": {},
   "source": [
    "# 20 sep 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278498cf-231f-4fd4-ad5a-384b90ef7496",
   "metadata": {},
   "source": [
    "# practice code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "16f0ac71-bc89-4d50-9a32-78d463136006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is a string', ' But is has punctuation. How can we remove it?']"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrase = 'This is a string! But is has punctuation. How can we remove it?'\n",
    "re.findall('[^!]+',test_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "2cbd4f51-d6d4-4e6f-b997-e715ce8bd9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "1c48e154-2ab9-4926-ab24-ee32ab11e4f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrase = 'This is a string! But is has punctuation. How can we remove it?'\n",
    "re.findall('[!$]+',test_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "dd80f9a0-f803-4946-9843-c30b33b6d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double ^ and & above 2 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0324cd4b-db15-4ba8-993d-3f1e2cd3926b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "11b2dfc4-f9a7-477d-b5d9-d72a0ad666bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'is',\n",
       " 'a',\n",
       " 'string',\n",
       " 'But',\n",
       " 'it',\n",
       " 'has',\n",
       " 'punctuation',\n",
       " 'How',\n",
       " 'can',\n",
       " 'we',\n",
       " 'remove',\n",
       " 'it']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_phrase = 'This is a string! But it has punctuation. How can we remove it?'\n",
    "re.findall('[^!.? ]+',test_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "4a1ec56f-8fd9-4bbe-bcf5-95161737a55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a string But it has punctuation How can we remove it'"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = ' '.join(re.findall('[^!.? ]+',test_phrase))\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b31ec86-ba98-434c-9a59-03a2bf26feae",
   "metadata": {},
   "source": [
    "## Brackets for Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "68624453-c86f-44d3-8bde-774c397962f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Only find the hypen-words in this sentence. But you do not know how long-ish they are'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "75bc6af9-c43c-443d-9a93-cb481ce2fbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hypen-words', 'long-ish']"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.findall(r'[\\w]+-[\\w]+',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ce4be5f0-81c0-4cad-bcbb-cc583aa8871d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n-words', 'g-ish']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if + not define then it give only a 1st character\n",
    "re.findall(r'[\\w]-[\\w]+',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "776fa9f8-79cb-42b8-a4b1-0288bad3e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /S non white space\n",
    "# small s for white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "12ca4bb9-9d6a-44ba-b1ed-e262e0f5b36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat']"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\S+at',\"The bat is here at.\")\n",
    "\n",
    "# bat me at se pehle space hai to wo non white space hai.\n",
    "# and /S print the non white space word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "4995a0fc-a36e-470e-b7b2-f690b26732f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['at', 'at']"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " re.findall(r'at',\"The bat is here at.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "8e92b014-0a38-4ec5-862b-05a2809ac502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat']"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " re.findall(r'\\Sat',\"The bat is here at.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178db034-1ece-4433-85c8-aed1683379c7",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4dfdc0-fa09-4b85-aa16-64c589fa1504",
   "metadata": {},
   "source": [
    "# 1. Print an f-string that displays NLP stands for Natural Language Processing using the variables provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "82d435df-46d9-4302-bb9b-9c9c87266790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP stands for Natural Language Processing using the Variables provided.\n"
     ]
    }
   ],
   "source": [
    "a = \"NLP stands for Natural Language Processing using the Variables provided.\"\n",
    "a = print(f\"{a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05915093-6337-4b72-bfbe-b950cd963b28",
   "metadata": {},
   "source": [
    "# 2. Create a file in the current working directory called contacts.txt by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "d457c709-80e9-4e1d-ae06-4c150d110eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting contacts.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile contacts.txt\n",
    "first_name\n",
    "last_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5a066c-cfa1-47ac-8103-ae64d6d6a25d",
   "metadata": {},
   "source": [
    "# 3. Open the file and use .read() to save the contents of the file to a string called fields. Make sure the file is closed at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e7afe99c-4152-4b0b-b892-398343d7da60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first_name\\nlast_name\\n'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 1\n",
    "string = open('contacts.txt')\n",
    "string.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "711e937f-84ab-4845-b2be-be8938710d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first_name\\nlast_name\\n'"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method 2) recommended by mam\n",
    "with open ('contacts.txt','r') as a:\n",
    "    fields = a.read()\n",
    "fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2045e0e-5d07-49de-a937-da26b372d530",
   "metadata": {},
   "source": [
    "# 4. Use PyPDF2 to open the file Business_Proposal.pdf. Extract the text of page 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "29916f4b-af9e-4980-a5c2-ee4dab0b16bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "bfc25b7d-748f-43bb-b2d1-1206649a593f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='C:\\\\Users\\\\Acer\\\\Downloads\\\\Business_Proposal.pdf'>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_path = r'C:\\Users\\Acer\\Downloads\\Business_Proposal.pdf'\n",
    "f = open(pdf_path, 'rb')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4c351429-0291-4cac-9ca7-8a83c89fe501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2._reader.PdfReader at 0x151042245d0>"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = PyPDF2.PdfReader(f)\n",
    "reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "32fadefe-5421-41d1-865c-c17504d457e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "0d86458d-e9f5-479e-9749-be1435486685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Type': '/Page',\n",
       " '/Parent': {'/Type': '/Pages',\n",
       "  '/Count': 2,\n",
       "  '/Kids': [IndirectObject(3, 0, 1447473333712),\n",
       "   IndirectObject(13, 0, 1447473333712)]},\n",
       " '/Resources': {'/Font': {'/F3': {'/Type': '/Font',\n",
       "    '/Subtype': '/TrueType',\n",
       "    '/Name': '/F3',\n",
       "    '/BaseFont': '/BCDFEE+Calibri',\n",
       "    '/Encoding': '/WinAnsiEncoding',\n",
       "    '/FontDescriptor': {'/Type': '/FontDescriptor',\n",
       "     '/FontName': '/BCDFEE+Calibri',\n",
       "     '/Flags': 32,\n",
       "     '/ItalicAngle': 0,\n",
       "     '/Ascent': 750,\n",
       "     '/Descent': -250,\n",
       "     '/CapHeight': 750,\n",
       "     '/AvgWidth': 521,\n",
       "     '/MaxWidth': 1743,\n",
       "     '/FontWeight': 400,\n",
       "     '/XHeight': 250,\n",
       "     '/StemV': 52,\n",
       "     '/FontBBox': [-503, -250, 1240, 750],\n",
       "     '/FontFile2': {'/Filter': '/FlateDecode', '/Length1': 144852}},\n",
       "    '/FirstChar': 32,\n",
       "    '/LastChar': 121,\n",
       "    '/Widths': [226,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     250,\n",
       "     0,\n",
       "     252,\n",
       "     0,\n",
       "     0,\n",
       "     507,\n",
       "     507,\n",
       "     507,\n",
       "     507,\n",
       "     507,\n",
       "     507,\n",
       "     507,\n",
       "     507,\n",
       "     507,\n",
       "     268,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     894,\n",
       "     579,\n",
       "     544,\n",
       "     533,\n",
       "     615,\n",
       "     488,\n",
       "     459,\n",
       "     0,\n",
       "     623,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     662,\n",
       "     517,\n",
       "     0,\n",
       "     543,\n",
       "     459,\n",
       "     487,\n",
       "     642,\n",
       "     567,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     0,\n",
       "     479,\n",
       "     525,\n",
       "     423,\n",
       "     525,\n",
       "     498,\n",
       "     305,\n",
       "     471,\n",
       "     525,\n",
       "     230,\n",
       "     0,\n",
       "     455,\n",
       "     230,\n",
       "     799,\n",
       "     525,\n",
       "     527,\n",
       "     525,\n",
       "     0,\n",
       "     349,\n",
       "     391,\n",
       "     335,\n",
       "     525,\n",
       "     0,\n",
       "     0,\n",
       "     433,\n",
       "     453]}},\n",
       "  '/ExtGState': {'/GS7': {'/Type': '/ExtGState', '/BM': '/Normal', '/ca': 1},\n",
       "   '/GS8': {'/Type': '/ExtGState', '/BM': '/Normal', '/CA': 1}},\n",
       "  '/ProcSet': ['/PDF', '/Text', '/ImageB', '/ImageC', '/ImageI']},\n",
       " '/MediaBox': [0, 0, 612, 792],\n",
       " '/Contents': {'/Filter': '/FlateDecode'},\n",
       " '/Group': {'/Type': '/Group', '/S': '/Transparency', '/CS': '/DeviceRGB'},\n",
       " '/Tabs': '/S',\n",
       " '/StructParents': 1}"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_two = reader.pages[1]\n",
    "page_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "d88ae7d7-6e86-4bdb-a3bc-999923b4b77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AUTHORS:  \\nAmy Baker, Finance Chair, x345, abaker@ourcompany.com  \\nChris Donaldson, Accounting Dir., x621, cdonaldson@ourcompany.com  \\nErin Freeman, Sr. VP, x879, efreeman@ourcompany.com  '"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extracting page 2\n",
    "page_two_text = page_two.extract_text()\n",
    "page_two_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b6c12-971f-4d78-a693-1afdecfa079f",
   "metadata": {},
   "source": [
    "# 5. Open the file contacts.txt in append mode. Add the text of page 2 from above to contacts.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "4a0123c4-5718-42f6-bb2d-236d77835739",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('contacts.txt', 'a') as a:\n",
    "    add_p2 = a.write(page_two_text)\n",
    "    add_p2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "e179fe9c-db67-4667-b5d9-1f04b1fb655f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'first_name\\nlast_name\\nAUTHORS:  \\nAmy Baker, Finance Chair, x345, abaker@ourcompany.com  \\nChris Donaldson, Accounting Dir., x621, cdonaldson@ourcompany.com  \\nErin Freeman, Sr. VP, x879, efreeman@ourcompany.com  '"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('contacts.txt', 'r') as a:\n",
    "    b = a.read()\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41e4c5-7f28-4ac9-8a2f-9edb94a56751",
   "metadata": {},
   "source": [
    "# 6. Using the page_two_text variable created above, extract any email addresses that were contained in the file Business_Proposal.pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "79dd5572-9b66-4ab3-97b5-b66a830e18ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abaker@ourcompany.com', 'cdonaldson@ourcompany.com', 'efreeman@ourcompany.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "# visualize        abaker           +@ ourcompany  + . com\n",
    "result = re.findall(pattern, page_two_text)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "7af661ca-7478-45b7-8f74-a619444d14aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abaker@ourcompany.com', 'cdonaldson@ourcompany.com', 'efreeman@ourcompany.com']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}'\n",
    "# visualize        abaker           +@ ourcompany  + . com\n",
    "result = re.findall(pattern, page_two_text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a755b1f-44be-4f75-9f91-2a72ca2753fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6487cf4-850e-44f5-a9e8-74fe3098a004",
   "metadata": {},
   "source": [
    "# What is escape sequence character?\n",
    "# and why we use r (raw string)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "c69a6563-6edf-4ee5-84f3-4c423c678baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escape sequences are special characters in strings that represent non-printable actions or formatting.\n",
    "# Escape means -> \"chhupana\"/hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "3882fd55-9391-49d7-ae32-58728804418f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "World\n"
     ]
    }
   ],
   "source": [
    "# 1. Normal String (Escape Characters Active):\n",
    "\n",
    "normal_string = \"Hello\\nWorld\"\n",
    "print(normal_string)\n",
    "\n",
    "# Escape Behavior: In this example, \\n is interpreted as a newline character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "b6656faf-b68c-47da-bcd2-116b8b306ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\\nWorld\n"
     ]
    }
   ],
   "source": [
    "# 2. Raw String (Escape Characters Not Active):\n",
    "#<----------------------------------------------->\n",
    "\n",
    "# raw string use krne se escape sequence character literal treat hota hai.\n",
    "# literal means wo character bhi show hoga escape ni hoga wo.\n",
    "\n",
    "raw_string = r\"Hello\\nWorld\"\n",
    "print(raw_string)\n",
    "\n",
    "# Escape Behavior: In this example, \\n is treated as a literal backslash followed by the letter n. No escape happens.\n",
    "\n",
    "# r\"string\" -> means that backslashes will not be interpreted as escape characters. Instead, they will be treated literally. \n",
    "# This is useful when dealing with regular expressions, file paths, or other scenarios where you want to avoid the usual escape behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022bc3cc-396b-4325-9834-08f3c2d5bb65",
   "metadata": {},
   "source": [
    "# 24 9 2024\n",
    "# spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "fe940e8c-9f53-43ef-a58f-eb34661d3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open Anaconda 3 (64-bit) -> Anaconda Prompt -> check python --version -> type here below 4 commands\n",
    "#<------------------------------------------------------------------------------------------------------->\n",
    "\n",
    "\n",
    "# Conda create -n spacy_env python=3.12.4  (python ka wo version dalna hai jo hmare laptop me hai so first check the python version)\n",
    "\n",
    "# conda activate spacy_env\n",
    "\n",
    "# conda install -c conda-forge spacy\n",
    "\n",
    "# python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "9f2a2171-d98b-4ca9-aa98-34881acfe349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "bb085bbb-cb71-4a86-907d-579dada94ad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 203, in _new_conn\n",
      "    sock = connection.create_connection(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\util\\connection.py\", line 60, in create_connection\n",
      "    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\socket.py\", line 962, in getaddrinfo\n",
      "    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "socket.gaierror: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 791, in urlopen\n",
      "    response = self._make_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 492, in _make_request\n",
      "    raise new_e\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 468, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 1097, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 611, in connect\n",
      "    self.sock = sock = self._new_conn()\n",
      "                       ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connection.py\", line 210, in _new_conn\n",
      "    raise NameResolutionError(self.host, self, e) from e\n",
      "urllib3.exceptions.NameResolutionError: <urllib3.connection.HTTPSConnection object at 0x000002A2CEBAD9D0>: Failed to resolve 'raw.githubusercontent.com' ([Errno 11001] getaddrinfo failed)\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 667, in send\n",
      "    resp = conn.urlopen(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py\", line 845, in urlopen\n",
      "    retries = retries.increment(\n",
      "              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\urllib3\\util\\retry.py\", line 515, in increment\n",
      "    raise MaxRetryError(_pool, url, reason) from reason  # type: ignore[arg-type]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A2CEBAD9D0>: Failed to resolve 'raw.githubusercontent.com' ([Errno 11001] getaddrinfo failed)\"))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\__main__.py\", line 4, in <module>\n",
      "    setup_cli()\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\cli\\_util.py\", line 87, in setup_cli\n",
      "    command(prog_name=COMMAND)\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\click\\core.py\", line 1157, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\typer\\core.py\", line 783, in main\n",
      "    return _main(\n",
      "           ^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\typer\\core.py\", line 225, in _main\n",
      "    rv = self.invoke(ctx)\n",
      "         ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\click\\core.py\", line 1688, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\click\\core.py\", line 1434, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\click\\core.py\", line 783, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\typer\\main.py\", line 683, in wrapper\n",
      "    return callback(**use_params)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\cli\\download.py\", line 44, in download_cli\n",
      "    download(model, direct, sdist, *ctx.args)\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\cli\\download.py\", line 85, in download\n",
      "    compatibility = get_compatibility()\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\cli\\download.py\", line 130, in get_compatibility\n",
      "    r = requests.get(about.__compatibility__)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\requests\\api.py\", line 73, in get\n",
      "    return request(\"get\", url, params=params, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\requests\\api.py\", line 59, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 589, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\requests\\sessions.py\", line 703, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\requests\\adapters.py\", line 700, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: /explosion/spacy-models/master/compatibility.json (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x000002A2CEBAD9D0>: Failed to resolve 'raw.githubusercontent.com' ([Errno 11001] getaddrinfo failed)\"))\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05e796ca-4590-470f-98a0-d26990003972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spacy and load the language library\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "8b9d847c-3528-43ef-8447-48d1b0d60243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla is looking at buying at buying U.S. startup for $6 million"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Doc object\n",
    "doc = nlp(r'Tesla is looking at buying at buying U.S. startup for $6 million')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "61304305-5f2a-4eb8-9cc6-1c06bc037e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# Print each token separately\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "7a83b5e9-594f-4793-bd13-4d6adba72891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x15106f83d10>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x15106f83cb0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x15105eec200>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1510715dbd0>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x15105e76490>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x15105eecc10>)]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "7fd5aca3-d151-491f-887b-1099f8eed244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "cff71f1f-73a4-4a00-8bab-52799791637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy is a pre trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fabe3067-748a-48fb-9554-2fe3c5148ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "708fab02-9554-4aa9-914a-307741d7cda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "# Create a string that includes opening and closing quotation marks\n",
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "bc9eed92-3719-4d9c-973f-447f43064f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We're moving to L.A.!\""
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Doc  object and explore tokens\n",
    "doc = nlp(mystring)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "c8fd4fd5-a972-485c-97bc-3e650afe3d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d5eb4-69c2-4c76-a8f5-fb1bd4ecf489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "00e55712-15f4-4ae2-b3b5-73e4fd29cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mycode ) without spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "1863d9da-7102-4e4d-9ec1-63e684e3b879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)\n",
    "\n",
    "# slash is not showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "a8d4780a-d81f-46f8-be45-d59a8e08c5df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"We're moving to L.A.!\""
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(mystring)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "549da643-ce8f-4afc-a56f-cc12b62e0e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fce2e4-99d2-417a-b119-25f4eb24911a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdab04ed-79d6-4e86-9de4-0aba576e8d98",
   "metadata": {},
   "source": [
    "# Prefixes, Suffixes and Infixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "88a4ba8c-37ab-453d-bbb3-1de87f9af13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(r\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "bb789937-1428-4a51-a63b-bd673536c627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snail\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for t in doc2:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d315663d-786c-4504-a7a5-8f1fe3c59ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy has 4 pretrained model.\n",
    "# we are using first model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "37ffa25d-26d8-433e-9713-7c30aa7108f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'A 5km NYC can ride costs $10.30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "9be7ca97-08ca-4b1e-b91e-efe8e92b6fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 5 km NYC can ride costs $ 10.30 "
     ]
    }
   ],
   "source": [
    "for t in doc3:\n",
    "    print(t, end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e3b47-9ce1-4191-b7f7-4358acfe4470",
   "metadata": {},
   "source": [
    "# Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "a0cca8c8-3e88-48db-ab9a-c61aebec6178",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(r\"Let's visit St. Louis in the U.S. next year.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5e4446-c074-4f01-b873-482cf2bf20b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc4 = nlp(r\"Let's visit st. Louis in the U.S. next year.\") try with small st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "3e081837-b171-4f2f-8ac2-e81323c77b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "bbe2f3f8-ab51-4aea-a7ff-627549aa5bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting Tokens\n",
    "len(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc439fd-a416-40ee-a7a6-a2a300b471e9",
   "metadata": {},
   "source": [
    "# Tokens can be retrieved by index position and slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "63be2a50-a58f-4a6f-8ee7-8d88e81c8509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing and slicing\n",
    "\n",
    "doc5 = nlp(u'It is better to give than to receive.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "134ba404-346d-4e07-965c-ecdaf1d0e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the third token:\n",
    "doc5[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "1baa79dd-f3b1-4370-ac9b-5a645a43b019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better to give"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[2:5] # last index not include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "e87c95e0-0c2b-45ec-a16c-c9f4c50c234f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "than to receive."
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc5[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ac041-6e4d-44f2-a266-4719a69f4bde",
   "metadata": {},
   "source": [
    "# Tokens cannot be reassigned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dde2e12b-6f86-47f6-9599-83b6fa22f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf377090-fea7-4abf-b770-bbcbce5d7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc6 = nlp(u'My dinner was horrible.')\n",
    "doc7 = nlp(u'Your dinner was delicious.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "653ac78c-2b13-41cd-a54e-dfa263200921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to change \"My dinner was horrible\" to \"My dinner was delicious\"\n",
    "# doc6[3] = doc7[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d2b0220-820f-41ee-a902-3d3834a86e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a8f5a-b8f4-4234-a0c4-3f33cc615800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# //Tokens cannot be reassigned\n",
    "# or // why we use tokenization\n",
    "\n",
    "# I ran out from the home. because we ran out to the milk.\n",
    "# isme dono ran ki different meaning hai.\n",
    "# ran -> iska meaning run\n",
    "# 2nd ran meaning -> khtm hona\n",
    "\n",
    "# so agr ek hi sentence me same word ke different meaning hai.\n",
    "# and agr hm ran ko run se replace krenge to to entence ka meaning wrong ho jayega.\n",
    "#     so hm replace ni kr skte \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b32f0-22b4-47c0-a141-eb15f4ea7da7",
   "metadata": {},
   "source": [
    "# Named Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62d17c4b-5039-4dd6-97fd-f9ec6c58737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# named entity recignition (ner)\n",
    "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10a19c06-56f7-4d1d-a60e-dadac144289e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "for token in doc8:\n",
    "    print(token.text, end=' | ')\n",
    "\n",
    "print('\\n----')\n",
    "\n",
    "for ent in doc8.ents: \n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b0ba98-5309-4474-8fc9-c39ccf3d2172",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc8' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ent \u001b[38;5;129;01min\u001b[39;00m doc8\u001b[38;5;241m.\u001b[39ments: \u001b[38;5;66;03m# doc8.ents <- this signifies name entity recognition\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ent\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39ment\u001b[38;5;241m.\u001b[39mlabel_\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(spacy\u001b[38;5;241m.\u001b[39mexplain(ent\u001b[38;5;241m.\u001b[39mlabel_)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc8' is not defined"
     ]
    }
   ],
   "source": [
    "# Explanation of above code\n",
    "#<---------------------------->\n",
    "# org -> organization\n",
    "# gpe -> geopolitical entity\n",
    "\n",
    "# + -> means concatenation\n",
    "# doc8.ents <- this signifies named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0af5e038-bde8-47ff-966b-5e436fb8f32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc8.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26cf92-2790-41b9-ab56-63e0a78df5a3",
   "metadata": {},
   "source": [
    "# 27 sep 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d1cd9c-7e4a-4538-a202-1143b7122d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noun chunks\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a83a2c2-e42f-4fa5-9f96-095ffe2c85fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonoumous cars\n",
      "insurance liability\n",
      "manufacturers\n"
     ]
    }
   ],
   "source": [
    "doc9 = nlp(u\"Autonoumous cars shift insurance liability toward manufacturers.\")\n",
    "for chunk in doc9.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d1823b-b83c-4c94-a613-8376d18400b1",
   "metadata": {},
   "source": [
    "# try with ruppee sign in previous code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dffdad0-c7db-480b-9925-08be9befd709",
   "metadata": {},
   "source": [
    "# ques: divide into tokens and find the grammer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f42ac5d-0ac2-4b16-b0d8-0ae7f06fc634",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc8 = nlp(u'Apple to build a Hong Kong factory for ₹6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4e51041-571c-4899-b272-78c032ac9e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | ₹ | 6 | million | "
     ]
    }
   ],
   "source": [
    "for token in doc8:\n",
    "    print(token.text, end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ca3ed7-fd58-4eeb-9539-7f878dca41b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "print('\\n----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1da4a8ed-c409-450b-9ac1-bf468ede99d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple - ORG - None\n",
      "Hong Kong - GPE - None\n",
      "₹6 million - MONEY - None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '383' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '384' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '394' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "for ent in doc8.ents: # doc8.ents <- this signifies name entity recognition\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label)))\n",
    "\n",
    "# This is known as named entity recognition\n",
    "# it can also show about date.\n",
    "\n",
    "# + sign means concatenation\n",
    "\n",
    "\n",
    "# Apple - ORG - None  -> org means organization\n",
    "# Hong Kong - GPE - None   ->  geopolitical entity\n",
    "# $6 million - MONEY - None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbfaa2bd-3f0f-4acd-9033-4b1a45f28c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc8.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecde6966-2b42-4794-b94e-4ff0dd1e0a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Red cars\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc10 = nlp(\"Red cars do not carry higher insurance rates.\")\n",
    "\n",
    "for chunk in doc10.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bddc925-73f8-4cda-b9b2-3e9bdd6b52c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "higher insurance rates\n",
      "higher insurance rates\n"
     ]
    }
   ],
   "source": [
    "doc11 = nlp(u\"He was a one_eyed, one-horned, flying, purple people-eater.\")\n",
    "\n",
    "for chuck in doc11.noun_chunks:\n",
    "    print(chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af323074-8f93-4498-8937-cf8bab0c365e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"39e1699624494bb4a918519212f9babc-0\" class=\"displacy\" width=\"1370\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,112.0 260.0,112.0 260.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,167.0 255.0,167.0 255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-2\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-3\" stroke-width=\"2px\" d=\"M290,222.0 C290,112.0 480.0,112.0 480.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M480.0,224.0 L488.0,212.0 472.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-4\" stroke-width=\"2px\" d=\"M620,222.0 C620,112.0 810.0,112.0 810.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M620,224.0 L612,212.0 628,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,167.0 805.0,167.0 805.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-6\" stroke-width=\"2px\" d=\"M510,222.0 C510,57.0 815.0,57.0 815.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M815.0,224.0 L823.0,212.0 807.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-7\" stroke-width=\"2px\" d=\"M510,222.0 C510,2.0 930.0,2.0 930.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M930.0,224.0 L938.0,212.0 922.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-8\" stroke-width=\"2px\" d=\"M1060,222.0 C1060,112.0 1250.0,112.0 1250.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,224.0 L1052,212.0 1068,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-9\" stroke-width=\"2px\" d=\"M1170,222.0 C1170,167.0 1245.0,167.0 1245.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,224.0 L1162,212.0 1178,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-39e1699624494bb4a918519212f9babc-0-10\" stroke-width=\"2px\" d=\"M950,222.0 C950,57.0 1255.0,57.0 1255.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-39e1699624494bb4a918519212f9babc-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1255.0,224.0 L1263.0,212.0 1247.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Built-in Visualizers\n",
    "\n",
    "# Visualizing the dependency parse\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
    "displacy.render(doc, style='dep',jupyter=True, options={'distance':110})\n",
    "\n",
    "# this diagram shows the relation between different tokens\n",
    "\n",
    "# explanation\n",
    "#<-------------->\n",
    "# A proper noun is a noun that names a specific person, place, or thing, and is always capitalized in English.\n",
    "\n",
    "# auxiliary verbs include \"is,\" \"am,\" \"are,\" \"was,\" \"were,\" \"have,\" \"has,\" \"had,\" \"do,\" and \"does.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "394a9a2d-b1f0-481e-b7af-3a59015032bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold neraly \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the entity recognizer\n",
    "\n",
    "doc = nlp(u\"Over the last quarter Apple sold neraly 20 thousand iPods for a profit of $6 million.\")\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62ae728-5cf6-4c82-91fa-96cb0eaacd17",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9173b5c6-6ec3-4ac1-ad97-aca3acf84afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# porter stemmer \n",
    "# snowball stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1355c123-e9a4-4f07-b6b8-ce2624991ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe54ee23-2f34-4334-a01a-3a2e12f81c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Porter Stemmer One of the most common - and effective - stemming tools is Porter's Algorithm developed by Martin Porter in 1980. The algorithm employs five phases of word reduction, each with its own set of mapping rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50db32e8-6225-43e7-b78f-d8961f63cbf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fairli\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "\n",
    "for word in words:\n",
    "    print(word+' --> '+p_stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709eaace-f731-427e-953f-4e67c33e7f7d",
   "metadata": {},
   "source": [
    "# Snowball Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34383836-4af8-47f0-baa4-b1d599d97301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is somewhat of a misnomer, as Snowball is the name of a stemming language developed by Martin Porter. The algorithm used here is more acurately called the \"English Stemmer\" or \"Porter2 Stemmer\". It offers a slight improvement over the original Porter stemmer, both in logic and speed. Since nltk uses the name SnowballStemmer, we'll use it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f08c64b-ce78-4839-ace3-4786dc6c3068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fair\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# The Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "\n",
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "523fa977-ba53-4a35-8cc3-2e87518275cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p_stemmer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPorter Stemmer:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(word\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m --> \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mp_stemmer\u001b[38;5;241m.\u001b[39mstem(word))\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSnowball Stemmer:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p_stemmer' is not defined"
     ]
    }
   ],
   "source": [
    "######### Comparison\n",
    "words = ['consolingly']\n",
    "\n",
    "print('Porter Stemmer:')\n",
    "for word in words:\n",
    "    print(word+' --> '+p_stemmer.stem(word))\n",
    "\n",
    "print('Snowball Stemmer:')\n",
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af012ee6-1a59-4eec-9fa6-0286ad7ed0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I --> i\n",
      "am --> am\n",
      "meeting --> meet\n",
      "him --> him\n",
      "tomorrow --> tomorrow\n",
      "at --> at\n",
      "the --> the\n",
      "meeting --> meet\n"
     ]
    }
   ],
   "source": [
    "##############\n",
    "\n",
    "phrase = 'I am meeting him tomorrow at the meeting'\n",
    "for word in phrase.split():\n",
    "    print(word+' --> '+p_stemmer.stem(word))\n",
    "\n",
    "\n",
    "# Here the word \"meeting\" appears twice - once as a verb, and once as a noun, and yet the stemmer treats both equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0670e90-4651-4c2c-b23b-9f93ca6dae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3213825d-a6c5-4ed9-92b0-886d1dfc2039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consolingly --> consolingli\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "words = ['consolingly']\n",
    "\n",
    "for word in words:\n",
    "    print(word+' --> '+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34eb1621-f255-41c8-be8e-2dd23f427923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consolingly --> consol\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "# The Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "words = ['consolingly']\n",
    "\n",
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6fd74f41-02e5-4be9-ac71-3b0b66a9e2e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer:\n",
      "consolingly --> consolingli\n",
      "Snowball Stemmer:\n",
      "consolingly --> consol\n"
     ]
    }
   ],
   "source": [
    "######### Comparison\n",
    "words = ['consolingly']\n",
    "\n",
    "print('Porter Stemmer:')\n",
    "for word in words:\n",
    "    print(word+' --> '+p_stemmer.stem(word))\n",
    "\n",
    "print('Snowball Stemmer:')\n",
    "for word in words:\n",
    "    print(word+' --> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cedd4-3d18-4fe9-ba16-704c16e8c9c5",
   "metadata": {},
   "source": [
    "# question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ab3dd51-e968-4fc6-b328-a089e20f0165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question\n",
    "# token\n",
    "# pos\n",
    "# porter stemmer\n",
    "\n",
    "# phrase = 'I am meeting him tomorrow at the meeting'\n",
    "# do above things in this sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0679a12b-fea9-4863-856c-52683f10728f",
   "metadata": {},
   "source": [
    "# solution using nltk mycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f694f22b-f11f-445e-bc10-996405051509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code1)\n",
    "phrase = 'I am meeting him tomorrow at the meeting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e887597d-382a-421e-acbb-a54d4f4d19d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code2)\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7958eb9-99d9-48f6-81ea-f8b58fe98d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code3) tokenize\n",
    "w = word_tokenize(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92a47f5-631d-43fb-a612-4c3167a6e852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'meeting', 'him', 'tomorrow', 'at', 'the', 'meeting']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85e7513b-3226-43b9-9d47-6ae6cd988a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code 4)\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d7f377-b833-4d01-8979-01bf98f41d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code5) pos\n",
    "p = pos_tag(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c260b7c2-a5d2-4ebd-8107-586fe10673dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('am', 'VBP'),\n",
       " ('meeting', 'VBG'),\n",
       " ('him', 'PRP'),\n",
       " ('tomorrow', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('meeting', 'NN')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40928770-d55b-4fc3-b726-3e981b71a34a",
   "metadata": {},
   "source": [
    "# Important ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cfd6c-34f2-4cc6-82c2-aa30b4cfd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question\n",
    "\n",
    "# 1) token\n",
    "# 2) pos\n",
    "# 3) porter stemmer\n",
    "\n",
    "# phrase = 'I am meeting him tomorrow at the meeting'\n",
    "# do above things in this sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d8717b1-78aa-4636-9368-306045bad97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7e4f191e-863f-4ef7-ac54-84ca334a879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = nlp('I am meeting him tomorrow at the meeting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b804c690-8d2d-49f5-a9d4-33aac86fade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase_tokens: ['I', 'am', 'meeting', 'him', 'tommorow', 'at', 'the', 'meeting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(phrase)\n",
    "print(f\"phrase_tokens: {words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cdfe8f77-e2ab-47a5-a47f-7504af371418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c5336c77091b4fe3933970861f44bc9b-0\" class=\"displacy\" width=\"930\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">am</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">meeting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">him</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">tomorrow</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">meeting</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5336c77091b4fe3933970861f44bc9b-0-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,57.0 265.0,57.0 265.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5336c77091b4fe3933970861f44bc9b-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5336c77091b4fe3933970861f44bc9b-0-1\" stroke-width=\"2px\" d=\"M180,167.0 C180,112.0 260.0,112.0 260.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5336c77091b4fe3933970861f44bc9b-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,169.0 L172,157.0 188,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5336c77091b4fe3933970861f44bc9b-0-2\" stroke-width=\"2px\" d=\"M290,167.0 C290,112.0 370.0,112.0 370.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5336c77091b4fe3933970861f44bc9b-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M370.0,169.0 L378.0,157.0 362.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5336c77091b4fe3933970861f44bc9b-0-3\" stroke-width=\"2px\" d=\"M290,167.0 C290,57.0 485.0,57.0 485.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5336c77091b4fe3933970861f44bc9b-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M485.0,169.0 L493.0,157.0 477.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5336c77091b4fe3933970861f44bc9b-0-4\" stroke-width=\"2px\" d=\"M290,167.0 C290,2.0 600.0,2.0 600.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5336c77091b4fe3933970861f44bc9b-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M600.0,169.0 L608.0,157.0 592.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5336c77091b4fe3933970861f44bc9b-0-5\" stroke-width=\"2px\" d=\"M730,167.0 C730,112.0 810.0,112.0 810.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5336c77091b4fe3933970861f44bc9b-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,169.0 L722,157.0 738,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c5336c77091b4fe3933970861f44bc9b-0-6\" stroke-width=\"2px\" d=\"M620,167.0 C620,57.0 815.0,57.0 815.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c5336c77091b4fe3933970861f44bc9b-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M815.0,169.0 L823.0,157.0 807.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2) pos\n",
    "\n",
    "# Built-in Visualizers\n",
    "\n",
    "# Visualizing the dependency parse\n",
    "\n",
    "from spacy import displacy\n",
    "\n",
    "doc = nlp(u'I am meeting him tomorrow at the meeting')\n",
    "displacy.render(doc, style='dep',jupyter=True, options={'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98129ee7-07b0-4154-86c1-1ad2ce515391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['I', 'am', 'meeting', 'him', 'tomorrow', 'at', 'the', 'meeting']\n",
      "I ----> i\n",
      "am ----> am\n",
      "meeting ----> meet\n",
      "him ----> him\n",
      "tomorrow ----> tomorrow\n",
      "at ----> at\n",
      "the ----> the\n",
      "meeting ----> meet\n"
     ]
    }
   ],
   "source": [
    "# 3) Porter Stemmer\n",
    "\n",
    "import nltk\n",
    "phrase = 'I am meeting him tomorrow at the meeting'\n",
    "\n",
    "# creating instance\n",
    "from nltk.stem.porter import *\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "# tokenze\n",
    "from nltk.tokenize import word_tokenize\n",
    "words  = word_tokenize(phrase)\n",
    "print(f\"words: {words}\")\n",
    "# Note: To apply porter stemmer words should be in tokenize form\n",
    "\n",
    "# applying porter stemmer\n",
    "for word in words:\n",
    "    print(f\"{word} ----> {p_stemmer.stem(word)}\")\n",
    "\n",
    "\n",
    "# Note: t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "408da1e7-b390-4758-bfe1-51756a737fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase_tokens: ['I', 'am', 'meeting', 'him', 'tommorow', 'at', 'the', 'meeting']\n",
      "I          ---> i\n",
      "am         ---> am\n",
      "meeting    ---> meet\n",
      "him        ---> him\n",
      "tommorow   ---> tommorow\n",
      "at         ---> at\n",
      "the        ---> the\n",
      "meeting    ---> meet\n"
     ]
    }
   ],
   "source": [
    "# 4) SnowballStemmer\n",
    "\n",
    "import nltk\n",
    "phrase = 'I am meeting him tommorow at the meeting'\n",
    "\n",
    "# creating instance\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "# tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(phrase)\n",
    "print(f\"phrase_tokens: {words}\")\n",
    "\n",
    "# applying SnowballStemmer\n",
    "for word in words:\n",
    "    print(f\"{word:10} ---> {s_stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b050c984-8cfc-43c9-9a85-8b742a6fd180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0506fd1a-38a0-41a2-9cb7-5b68f9275d03",
   "metadata": {},
   "source": [
    "# LEMMETIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "517847cc-3133-41e2-84a4-a6f213cdf224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9cf63f29-b73e-4158-bb74-db01ffc5c23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c8b78bbe-f935-4346-beb0-69a96e7e3171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t 95 \t 4690420944186131903 \t I\n",
      "am \t 87 \t 10382539506755952630 \t be\n",
      "a \t 90 \t 11901859001352538922 \t a\n",
      "runner \t 92 \t 12640964157389618806 \t runner\n",
      "running \t 100 \t 12767647472892411841 \t run\n",
      "in \t 85 \t 3002984154512732771 \t in\n",
      "a \t 90 \t 11901859001352538922 \t a\n",
      "race \t 92 \t 8048469955494714898 \t race\n",
      "because \t 98 \t 16950148841647037698 \t because\n",
      "I \t 95 \t 4690420944186131903 \t I\n",
      "love \t 100 \t 3702023516439754181 \t love\n",
      "to \t 94 \t 3791531372978436496 \t to\n",
      "run \t 100 \t 12767647472892411841 \t run\n",
      "since \t 98 \t 10066841407251338481 \t since\n",
      "I \t 95 \t 4690420944186131903 \t I\n",
      "ran \t 100 \t 12767647472892411841 \t run\n",
      "today \t 92 \t 11042482332948150395 \t today\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text, '\\t', token.pos, '\\t', token.lemma, '\\t', token.lemma_)\n",
    "\n",
    "# \\t for tab \n",
    "\n",
    "# explanation in pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6b3cccef-2ffa-461b-9b9e-1d00e5e452ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# token.text: The original text of the token (the exact word as it appears in the input)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b806810-a0e5-4c2b-85b1-a43e4c260aea",
   "metadata": {},
   "source": [
    "# FUNCTION TO DISPLAY LEMMAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "af494825-7973-4a77-b50d-23f9cbc12207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON      4690420944186131903 I\n",
      "saw          VERB     11925638236994514241 see\n",
      "eighteen     NUM       9609336664675087640 eighteen\n",
      "mice         NOUN      1384165645700560590 mouse\n",
      "today        NOUN     11042482332948150395 today\n",
      "!            PUNCT    17494803046312582752 !\n"
     ]
    }
   ],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:{22}} {token.lemma_}')\n",
    "\n",
    "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f819a005-d54b-4b2e-8178-42f73991139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the lemma of saw is see, mice is the plural form of mouse, and yet\n",
    "# eighteen is its own number, not an expanded form of eight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b9f838ec-d390-4e0f-ba40-b0ed418a2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"I am meeting him tomorrow at the meeting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7a864163-bb47-4fac-bad5-8a63516461b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON      4690420944186131903 I\n",
      "am           AUX      10382539506755952630 be\n",
      "meeting      VERB      6880656908171229526 meet\n",
      "him          PRON      1655312771067108281 he\n",
      "tomorrow     NOUN      3573583789758258062 tomorrow\n",
      "at           ADP      11667289587015813222 at\n",
      "the          DET       7425985699627899538 the\n",
      "meeting      NOUN     14798207169164081740 meeting\n",
      ".            PUNCT    12646065887601541794 .\n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "74575d15-2594-4f62-885e-d6714aa2fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"That's an enourmous automobile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1341d897-efdb-460c-984b-296421975ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That         PRON      4380130941430378203 that\n",
      "'s           AUX      10382539506755952630 be\n",
      "an           DET      15099054000809333061 an\n",
      "enourmous    ADJ       6049941145525601847 enourmous\n",
      "automobile   NOUN      7211811266693931283 automobile\n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc4)\n",
    "\n",
    "# last row in lemmas row\n",
    "\n",
    "# be means irregular verb -> means ye sb ke sath use ho skta hai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5984e6-a246-45ac-83b9-b5bf822d7a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54f6084c-c7e6-42cb-8056-574c28058bab",
   "metadata": {},
   "source": [
    "# Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31dbb1f6-307b-4184-a751-07e68da3e623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words like \"a\" and \"the\" appear so frequently that they don't require tagging as\n",
    "# thoroughly as nouns, verbs and modifiers. We call these stop words, and they can be \n",
    "# filtered from the text to be processed. spaCy holds a built-in list of some 305 English \n",
    "# stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654019a6-4ed2-44d8-8a9b-8a81ada507ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports:\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d724a423-3b83-4d63-9bd0-f2e9b03f135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hereafter', 'none', 'perhaps', 'anyone', 'former', 'during', 'even', 'been', 'always', 'ever', 'against', 'be', 'since', 'n‘t', 'you', 'when', 'up', 'with', 'full', 'get', 'last', 'enough', 'between', 'whom', 'his', 'various', 'himself', 'towards', 'whereupon', 'and', 'wherever', 'are', 'under', 'also', 'all', 'move', 're', 'together', 'that', 'nor', 'make', 'me', 'one', 'everyone', 'few', 'in', 'except', 'has', 'no', 'else', 'formerly', 'where', 'by', 'those', 'without', 'still', 'twelve', 'never', 'who', 'third', 'everything', 'its', 'therefore', 'via', 'eleven', 'but', 'well', 'fifty', 'two', 'somehow', 'on', 'nine', 'go', 'ourselves', 'your', 'along', 'part', 'used', 'three', 'almost', 'yourself', 'will', 'across', 'becoming', 'or', 'our', 'each', 'bottom', 'give', 'say', \"'m\", '’ll', 'there', 'seems', 'seem', 'whither', 'hundred', 'for', 'her', 'i', 'whole', '‘ll', 'was', 'four', 'out', 'serious', 'hereupon', 'noone', 'it', 'themselves', 'toward', 'not', 'anywhere', 'throughout', 'neither', 'although', '‘ve', 'namely', 'besides', 'eight', 'both', 'call', 'anyway', 'them', 'alone', 'due', 'six', 'several', 'below', 'above', '‘s', \"n't\", 'so', 'nowhere', 'meanwhile', 'nothing', 'yours', 'whereby', 'ca', 'have', 'someone', 'these', 'another', '‘re', 'once', 'became', 'quite', 'were', 'within', 'elsewhere', 'among', 'wherein', 'is', 'of', 'indeed', 'front', 'whoever', 'keep', '‘d', 'would', 'over', \"'re\", 'sometime', 'here', 'whatever', 'than', 'done', 'somewhere', 'seemed', \"'s\", 'being', 'ours', 'can', 'made', 'should', 'itself', 'onto', 'show', 'down', 'however', 'they', 'take', 'yet', 'does', 'at', 'whence', 'forty', 'upon', 'hers', 'thence', 'name', 'other', 'either', 'until', '’m', 'ten', 'us', 'the', 'very', 'many', 'may', 'least', 'next', 'hereby', 'into', 'side', 'thru', 'seeming', 'latterly', 'back', 'most', 'amount', 'unless', 'anyhow', 'might', 'every', 'hence', 'sixty', 'because', 'less', 'please', 'any', \"'d\", '’re', 'afterwards', 'latter', 'around', 'five', 'nobody', 'whenever', 'must', 'he', 'twenty', 'then', 'this', \"'ve\", 'rather', 'whether', 'now', 'do', 'own', '’d', 'whose', 'thus', 'while', 'put', 'see', 'behind', 'often', 'again', 'which', 'whereas', 'therein', 'from', 'beside', 'moreover', 'herself', 'more', 'she', 'about', 'amongst', 'as', 'everywhere', 'empty', 'such', 'him', 'thereafter', 'doing', 'using', '’ve', 'something', 'n’t', 'am', \"'ll\", 'if', 'per', 'why', 'how', '‘m', 'my', 'fifteen', 'a', 'did', 'sometimes', 'we', 'an', 'to', 'yourselves', 'had', 'already', 'otherwise', 'top', 'myself', 'thereupon', 'mostly', 'too', 'only', 'after', 'just', 'btw', 'through', 'really', 'anything', 'becomes', 'nevertheless', 'others', 'same', 'beforehand', 'before', 'much', 'regarding', 'first', 'herein', 'mine', 'their', 'cannot', '’s', 'whereafter', 'thereby', 'some', 'what', 'become', 'could', 'though', 'further', 'off'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "729e4aad-2ab3-449e-8527-8407a032effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the set of spaCy's default stop words (remember that sets are unordered):\n",
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b0b5be8-afd4-4819-a203-0991e475f2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see if a word is stop word\n",
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13eefc9f-45e0-492b-8f8b-aad88b3e357c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dec723a5-5f48-4480-a016-7fcd9911b4b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop\n",
    "\n",
    "# btw (by the way) is not a stop word.\n",
    "# so we will add it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c256ef4-6258-47b9-886f-8e3d82cde6fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde86d73-1113-4799-a69a-c125440688f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bbac2fa0-c5e1-41fe-9006-a1a406684750",
   "metadata": {},
   "source": [
    "# To add a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2e07561-c86d-46ca-a140-968bdd0bf4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There may be times when you wish to add a stop word to the default set. Perhaps you\n",
    "# decide that 'btw' (common shorthand for \"by the way\") should be considered a stop word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecd063a6-7b99-4705-9964-e8ceda42512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the word to the set of stop words. Use lowercase()\n",
    "nlp.Defaults.stop_words.add('btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5669f144-77da-45db-9b64-822a7181cd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fda451eb-bfd0-4291-8fcb-7c2eec4f98a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# //len se pta chl jayega add hua hai ya nhi.\n",
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e638112-377d-4de6-9171-22bab8cac923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc4befee-8fc8-43d1-ba08-e4473f4a8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: When adding stop words, always use lowercase. Lexemes are converted to lowercase \n",
    "# before being added to vocab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2800bf-9436-4f73-a953-e0829e3c90e5",
   "metadata": {},
   "source": [
    "# To remove a stop word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "495b5fe2-0b8e-4b0f-9b52-f733eaecab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word from the set of stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "463c4920-eac0-4f09-8a91-c6e0834d18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the stop_word tag from the lexeme\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a422244a-290d-453f-9ffb-6a7417d5fef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50720c2d-d8d4-49fc-973c-99c51b569f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e04c3753-275e-4240-ac9b-08c764c5db91",
   "metadata": {},
   "source": [
    "# Vocabulary and Phrase Matching in NLP Python | nlp.vocab Phrasematcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bd01992f-3838-4e57-80fb-dd922efd22e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# match on any part of the token inculding text and annotations,\n",
    "# and you can add multiple patterns to the same matcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b347361-3638-4c68-9c30-59af08ea9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfor standard imports\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30b3fd2a-ff1c-4641-8a94-555517da0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc1c98be-1a19-41be-b4c6-89b809ed54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here matcher is an object that pairs to the current vocab object. We can add and remove\n",
    "# specific named matcher as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b27eaf2-0a55-48e4-b5c3-b2ce5474dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER':'power'}]\n",
    "\n",
    "# {'IS_PUNCT': True} -> True means any punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdd1f297-cae2-4263-8437-b17d32f4a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower', [pattern1, pattern2, pattern3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a337b72d-5605-47bb-8b63-4ed7781a7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow a solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1c4ccb8-2972-42b6-9957-b77485ba506b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 9), (8656102463236116519, 11, 14)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24b0f70-8d18-4f17-a24b-804d283669fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519 SolarPower 1 3 Solar Power\n",
      "8656102463236116519 SolarPower 8 9 solarpower\n",
      "8656102463236116519 SolarPower 11 14 Solar-power\n"
     ]
    }
   ],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44fd911-67ef-44da-9147-5889f919807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8656102463236116519,     1,     3\n",
      "8656102463236116519,     8,     9\n",
      "8656102463236116519,    11,    14\n"
     ]
    }
   ],
   "source": [
    "# mycode\n",
    "for match_id, start, end in found_matches:\n",
    "    print(f\"{match_id:5}, {start:5}, {end:5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1995a2-4262-4744-a235-f243b1a9994c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5591c8e7-cd35-4b93-9b01-4e285fd76067",
   "metadata": {},
   "source": [
    "# Redefine the patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e21c601-a307-4e21-a348-d9dbbd974787",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP':'*'},{'LEMMA': 'power'}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7652211-3aa7-4590-b3eb-62dce1dad657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new set of patterns to the 'SolarPower' matcher:\n",
    "matcher.add('SolarPower', [pattern1, pattern2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e91fb18c-f567-49a0-a948-e8bedcc7b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(8656102463236116519, 1, 3), (8656102463236116519, 8, 9), (8656102463236116519, 11, 14)]\n"
     ]
    }
   ],
   "source": [
    "found_matches = matcher(doc)\n",
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e021d19-5522-4394-b9ab-2ab13985ec72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# op lgane se words ke between me kuch bhi ho. like space, hyphen it will be idenfy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe9a5e-8316-46de-94c2-2403aa28b72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a390796-2d37-4c0f-9637-402c48c7e882",
   "metadata": {},
   "source": [
    "# Remove the old patterns to avoid duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75d15d4d-0766-4035-932a-05d1e19f2512",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.remove('SolarPower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c90cdd6d-b0b7-45ee-b57e-a2020b9eaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower', [pattern1, pattern2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5207cce3-07eb-4e08-b1c5-6199329a82f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Solar--powered energy runs solar-powered cars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d17c3bb-5907-47a9-8369-2b1cc7ba5d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8656102463236116519, 0, 3), (8656102463236116519, 5, 8)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_matches = matcher(doc2)\n",
    "found_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba98e06-e5f3-4ca7-ba52-d0c2b69be39c",
   "metadata": {},
   "source": [
    "# QUESTION HOMEWORk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee5d73ee-86cf-4cc8-bbad-167295d62db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10166658444968339366 DS Terms 3 5 machine learning\n",
      "10166658444968339366 DS Terms 6 8 artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "# Ques: search machine learning, artificail intelligence and deep learning from the input/given text\n",
    "\n",
    "# I will learn machine learning and artificial intelligence.\n",
    "# Note: dl is not in text. so there will no match for dl.\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern1 = [{'LOWER':'machinelearning'}] # also match if without space\n",
    "pattern2 = [{'LOWER':'machine'}, {'LOWER':'learning'}] # also match if space between them\n",
    "pattern3 = [{'LOWER':'machine'}, {'IS_PUNCT':True, 'OP':'*'}, {'LOWER':'learning'}] # also match if punct and op match-> if other symbols with any occurrence\n",
    "\n",
    "pattern4 = [{'LOWER':'artificialintelligence'}]\n",
    "pattern5 = [{'LOWER':'artificial'}, {'LOWER':'intelligence'}]\n",
    "pattern6 = [{'LOWER':'artificial'}, {'IS_PUNCT':True, 'OP':'*'}, {'LOWER':'intelligence'}]\n",
    "\n",
    "pattern7 = [{'LOWER':'deeplearning'}]\n",
    "pattern8 = [{'LOWER':'deep'}, {'LOWER':'learning'}]\n",
    "pattern9 = [{'LOWER':'deep'}, {'IS_PUNCT':True, 'OP':'*'}, {'LOWER':'learning'}]\n",
    "matcher.add(\"DS Terms\", [pattern1, pattern2, pattern3,\n",
    "                        pattern4, pattern5, pattern6,\n",
    "                        pattern7, pattern8, pattern9])\n",
    "\n",
    "doc = nlp(\"I will learn machine learning and artificial intelligence\")\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "# found_matches\n",
    "\n",
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(match_id, string_id, start, end, span.text)\n",
    "\n",
    "\n",
    "# op means operator\n",
    "# * star in op -> means allowed zero or more time occurrences of a pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc5ac3-fd34-4925-ade0-dd98dadc7522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd751169-65be-433d-b176-b89a821bd390",
   "metadata": {},
   "source": [
    "# 4 oct 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c70ddb-2aba-4839-8d3a-e230269dd527",
   "metadata": {},
   "source": [
    "# Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4cffc-1261-4a3f-8f76-0c8e0a795717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Matcher is a token-based rule matcher that allows you to match sequences of tokens (words) using\n",
    "# patterns. Each pattern defines the atteributes (like part of speech, lemma, orthography, etc.) of the tokens\n",
    "# you want to match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68feded-d7af-49d9-924d-8b24c8a8712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f7cf8a-8b1e-49a8-84b2-ae63f227fff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "# Create a Matcher object\n",
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39bca557-9c1c-446a-ba72-de83824c0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pattern to match adjectives followed by nouns\n",
    "pattern = [{\"POS\":\"ADJ\"},{\"POS\":\"NOUN\"}]\n",
    "matcher.add(\"ADJ_NOUN_PATTERN\",[pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803e0164-3f46-4241-b93f-f8a9c619e4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5488211386492616699, 3, 5), (5488211386492616699, 7, 9)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the matcher to the text\n",
    "doc = nlp(\"I saw a beautiful cat and a happy dog.\")\n",
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514dd90-9f4c-484a-92d7-af5407ca3915",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f526360-ca5e-48fb-9dd9-b945c7c1b188",
   "metadata": {},
   "source": [
    "# Phrase Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "61190d6e-bd03-4ce6-af9c-e3021ca384f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The PhraseMatcher is simpler than Matcher and is used to match exact sequences of words or phrases\n",
    "# in a document. It's designed to efficiently matcg large sets of exact phrases witin a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40843e22-7182-4776-864d-faab494616d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "# Create a PhraseMatcher object\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a72b73a0-967a-488e-aaa6-63a71ea2cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define phrases to match\n",
    "phrases = [\"beautiful cat\", \"happy dog\"]\n",
    "patterns = [nlp(text) for text in phrases]\n",
    "phrase_matcher.add(\"ANIMAL_PATTERN\",patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d4602d62-1162-4261-bf6a-e0366ede03aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18232475512666784510, 3, 5), (18232475512666784510, 7, 9)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"I saw a beautiful cat and a happy dog.\")\n",
    "matches = phrase_matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "162a7553-a8c6-4189-a605-bbbfd29ca4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case: Best used when you want to search for exact phrases or named entities in a large dataset. It's faster and more effiecient when you \n",
    "# need to match a large set of known phrases like proper nouns, names, or technical terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf3e8d1-b038-4a4c-8509-5abe279be519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa58ea46-e088-473a-b17c-a87077cb4008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c95bd4d-1a61-4779-a0ee-770e34ced371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12372185-7872-4c1c-ae9c-49a4a4d54ae0",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9295dd2c-56dd-4b91-ae35-ed6b36b2943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reaganomics\n",
    "#<--------------->\n",
    "\n",
    "phrases = ['voodoo economics', 'tricke-down economics', 'free-market economics']\n",
    "\n",
    "# apply phrase matcher of these 4 words on the reagaonomics.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5ca49fe6-ecc1-4dd4-9807-6418f15e37dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4a7e340-3c3a-4b6e-a304-8f32e396e5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "# Create a PhraseMacher object\n",
    "phrase_matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "08ec1852-129f-4e1d-b635-4d9a15fcebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define phrases to match\n",
    "phrases = ['voodoo economics', 'tricke-down economics', 'free-market economics']\n",
    "patterns = [nlp(text) for text in phrases]\n",
    "phrase_matcher.add(\"REAGONOMICS_PATTERN\",patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07ddce2f-1381-4a25-a9cb-bf4f55fc3b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open file + creating doc object\n",
    "#<--------------------------------->\n",
    "\n",
    "with open('reaganomics.txt', 'r') as f:\n",
    "    doc3 = nlp(f.read()) \n",
    "\n",
    "# Note: we can create doc object individually too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e06c39d8-1939-444a-b759-b51ee2b9f57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7351381812350814543, 54, 56), (7351381812350814543, 61, 65)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = phrase_matcher(doc3)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61663c56-ef9b-4794-b247-bc54801900ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dff35-6103-464e-bd26-0984cdf96ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08dfa8ba-d887-427f-81f1-878647fafc5f",
   "metadata": {},
   "source": [
    "# 9 oct 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5c963-7ca1-43a5-b31b-a6ba917a0b55",
   "metadata": {},
   "source": [
    "# POS & NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb466346-4887-4e4b-a20d-bd80d0c70dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Part of Speech Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b5d44d-26fd-43cf-a749-0aebfc3e8ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perfom standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64dcbeb4-a2e2-4171-84b4-87d1137380b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple Doc object\n",
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee2d4a6f-f63b-45d1-9df0-6599ba0490d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  View token tags \n",
    "# Recall that you can obtain a particular token by its index position.\n",
    "\n",
    "# To view the coarse POS tag use token.pos_\n",
    "# To view the fine-grained tag use token.tag_\n",
    "# To view the description of either type of tag ue spacy.explain(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65ea4fe8-f234-4a60-b4c1-49f30d666c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumped over the lazy dog's back\n"
     ]
    }
   ],
   "source": [
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2357b8d6-cda6-4e56-b097-1ca98378b5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped VERB VBD verb, past tense\n"
     ]
    }
   ],
   "source": [
    "# Print the fifth word and associated tags:\n",
    "print(doc[4].text, doc[4].pos_, doc[4].tag_, spacy.explain(doc[4].tag_))\n",
    "\n",
    "      # post grain pos, find grain pos\n",
    "\n",
    "# ..VBD means verb past tense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ccde5c8-9b4a-41cb-865d-e87eaca928ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The        DET      DT     determiner\n",
      "quick      ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "brown      ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "fox        NOUN     NN     noun, singular or mass\n",
      "jumped     VERB     VBD    verb, past tense\n",
      "over       ADP      IN     conjunction, subordinating or preposition\n",
      "the        DET      DT     determiner\n",
      "lazy       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "dog        NOUN     NN     noun, singular or mass\n",
      "'s         PART     POS    possessive ending\n",
      "back       NOUN     NN     noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "392350d5-2098-418a-929c-f978cf5d7093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanation of above code\n",
    "#<---------------------------->\n",
    "\n",
    "# 1. token.text: The actual word (or token) from the text.\n",
    "# 2. token.pos_: The coarse-grained part of speech (POS). This is a simple, high-level categorization of the token, such as 'NOUN', 'VERB', 'ADJ', etc.\n",
    "# 3. token.tag_: The fine-grained POS tag. This is a more detailed categorization that includes \n",
    "# tense, number, case, etc. It follows the specific conventions of the language model being used (for English, often the Universal Dependencies tagset or Penn Treebank tagset).\n",
    "# 4. spacy.explain(token.tag_): This function gives a human-readable explanation of the fine-grained POS tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "143eb640-a1a9-4980-9ec5-7ec3560e100a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jumped 100 17109001835818727656\n"
     ]
    }
   ],
   "source": [
    "# when we not use hyphen the number will print\n",
    "\n",
    "print(doc[4].text, doc[4].pos, doc[4].tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "145490a0-23a2-4457-a9bc-0c1cc58ac222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'I read books on NLP.')\n",
    "r = doc[1]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73777456-efe6-4f60-ba93-1e89d958429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB     VBP    verb, non-3rd person singular present\n"
     ]
    }
   ],
   "source": [
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "234d37de-f830-47e8-8511-037bcef5d419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'I read a book on NLP.')\n",
    "r = doc[1]\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c90cf67-ddbf-472a-861d-5c24e80a366a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB     VBD    verb, past tense\n"
     ]
    }
   ],
   "source": [
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9047dcb0-d99d-49d5-ac78-ee242bf941c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I          PRON     PRP    pronoun, personal\n",
      "read       VERB     VBD    verb, past tense\n",
      "a          DET      DT     determiner\n",
      "book       NOUN     NN     noun, singular or mass\n",
      "on         ADP      IN     conjunction, subordinating or preposition\n",
      "NLP        PROPN    NNP    noun, proper singular\n",
      ".          PUNCT    .      punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "# u'I read books on NLP. -> full sentence \n",
    "\n",
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b67029-8d78-4037-b68b-d26f4edbedf7",
   "metadata": {},
   "source": [
    "# Counting POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59650469-f3d1-42c0-80bb-53a43619b8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Doc.count_by() method accepts a specific token attribute as its\n",
    "# argument, and returns a frequency count of the given attribute as a \n",
    "# dictionary object. Keys in the dictionary are the integer values of \n",
    "# the given attribute ID, and values re the frequency. Counts of zero \n",
    "# are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da6f5f23-9529-4692-99fc-4ee5e45ce693",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped overt the lazy do's back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "efbdfd69-ecf7-4351-8461-fa860eefd292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{90: 2, 84: 3, 92: 2, 100: 2, 87: 1, 86: 1, 97: 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the frequencies of different coarse-grained POS tags:\n",
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e49a29d9-c13c-4b74-ad28-679e598374f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DET'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[90].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "15d1541a-85b9-4472-a744-996feeba8bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADJ'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[84].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d7d911e0-544a-4e64-b1c0-1c3acc0428b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create a frequency list of POS tags from the entire document \n",
    "# Since POS_counts returns a dictionary, we cna obtain a list of keys \n",
    "# with POS_counts.items().\n",
    "# By sorting the list we have access to the tag and its count, in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5a62fbd-0fe6-4ea9-b895-7ca8f318108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ  : 3\n",
      "86. ADV  : 1\n",
      "87. AUX  : 1\n",
      "90. DET  : 2\n",
      "92. NOUN : 2\n",
      "97. PUNCT: 1\n",
      "100. VERB : 2\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{5}}: {v}')\n",
    "\n",
    "# //k,v it is a key value pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd00725-dd92-4fe2-a124-21fbc63389c0",
   "metadata": {},
   "source": [
    "# Count the different fine-grained tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ebd84cad-6fdc-42f9-aa2e-d94a5979c88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"The quick brown fox jumped overt the lazy dog's back.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61c03734-fd16-46c6-907c-f2cfe136c301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{15267657372422890137: 2,\n",
       " 10554686591937588953: 3,\n",
       " 15308085513773655218: 3,\n",
       " 17109001835818727656: 1,\n",
       " 14200088355797579614: 1,\n",
       " 74: 1,\n",
       " 12646065887601541794: 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TAG_counts = doc.count_by(spacy.attrs.TAG)\n",
    "TAG_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fae051d5-0a50-438f-9911-90f3df5ca81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.POS :1\n",
      "10554686591937588953.JJ  :3\n",
      "12646065887601541794..   :1\n",
      "14200088355797579614.VB  :1\n",
      "15267657372422890137.DT  :2\n",
      "15308085513773655218.NN  :3\n",
      "17109001835818727656.VBD :1\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}.{doc.vocab[k].text:{4}}:{v}')\n",
    "    \n",
    "\n",
    "# doubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb194298-4c9d-4dc0-a99b-a7f781da40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# / *****TAG_counts = doc.count_by(spacy.attrs.TAG):\n",
    "\n",
    "# This line coutns the occurrences of each syntactic tag in the doc\n",
    "# object using spaCy's count_by() method and stores the result in \n",
    "# TAG_counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0395415e-1e20-45a4-8a19-f03705f4c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Why did the ID numbers get so big?** In spaCy, certain text values \n",
    "# are hardcoded ino 'Doc.vocab' and take up the first several hundred \n",
    "# ID numbers. Strings like 'NOUN and 'VERB' are used frequently by \n",
    "# internal operations. Other , like fine-grained tags, are assigned has \n",
    "# values as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0dfa82f0-902c-4ff2-b8ab-fcc16198da19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the different dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "705fef6d-3614-42c7-86b1-212744ca5a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEP_counts = doc.count_by(spacy.attrs.DEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "028496c9-5656-49dd-ad92-d711e4260a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402. amod: 3\n",
      "415. det : 2\n",
      "416. dobj: 1\n",
      "429. nsubj: 1\n",
      "440. poss: 1\n",
      "445. punct: 1\n",
      "450. xcomp: 1\n",
      "8110129090154140942. case: 1\n",
      "8206900633647566924. ROOT: 1\n"
     ]
    }
   ],
   "source": [
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f'{k}. {doc.vocab[k].text:{4}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da747c98-5170-44e4-a0c6-80183bd7ecc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9c9dc-ce9c-4524-9451-e0a57c02fba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2358f5ae-28c6-4b69-a911-5875bbc978e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizing Parts of Speech\n",
    "# spacy offers an outstanding visualizer called displacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c22cda6-2c0f-4ff9-a5ac-2912a4d1879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9b52a83-f99c-4ccb-b96b-797e37f1fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the displaCy library\n",
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ffd77dc-a4d9-40ae-bba8-b3c7fbe0b961",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc  = nlp(u\"The quick brown fox jumped overt the lazy dog's back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fba5848-4618-4689-be79-f7987a6fd44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"34643f65a8ac43a5ab5010a5f279da83-0\" class=\"displacy\" width=\"1260\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">overt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">back</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,57.0 375.0,57.0 375.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,112.0 370.0,112.0 370.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-2\" stroke-width=\"2px\" d=\"M290,222.0 C290,167.0 365.0,167.0 365.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,224.0 L282,212.0 298,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-3\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-4\" stroke-width=\"2px\" d=\"M510,222.0 C510,167.0 585.0,167.0 585.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M585.0,224.0 L593.0,212.0 577.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,112.0 920.0,112.0 920.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-6\" stroke-width=\"2px\" d=\"M840,222.0 C840,167.0 915.0,167.0 915.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,224.0 L832,212.0 848,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-7\" stroke-width=\"2px\" d=\"M620,222.0 C620,57.0 925.0,57.0 925.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,224.0 L933.0,212.0 917.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-8\" stroke-width=\"2px\" d=\"M950,222.0 C950,167.0 1025.0,167.0 1025.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1025.0,224.0 L1033.0,212.0 1017.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-34643f65a8ac43a5ab5010a5f279da83-0-9\" stroke-width=\"2px\" d=\"M620,222.0 C620,2.0 1150.0,2.0 1150.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-34643f65a8ac43a5ab5010a5f279da83-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150.0,224.0 L1158.0,212.0 1142.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance':110})\n",
    "\n",
    "# explanation -> distance is for gap between the toekns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17a9a6c1-eaad-4c46-817b-b1ca51a43724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"342d4aa2e83b46ca9796762d412d1888-0\" class=\"displacy\" width=\"1260\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: Yellow; background: red; font-family: times; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">overt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">back</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-0\" stroke-width=\"2px\" d=\"M62,222.0 62,167.0 377.0,167.0 377.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,224.0 L58,216.0 66,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-1\" stroke-width=\"2px\" d=\"M172,222.0 172,185.33333333333334 374.0,185.33333333333334 374.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M172,224.0 L168,216.0 176,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-2\" stroke-width=\"2px\" d=\"M282,222.0 282,203.66666666666666 371.0,203.66666666666666 371.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M282,224.0 L278,216.0 286,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-3\" stroke-width=\"2px\" d=\"M392,222.0 392,203.66666666666666 481.0,203.66666666666666 481.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M392,224.0 L388,216.0 396,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-4\" stroke-width=\"2px\" d=\"M502,222.0 502,203.66666666666666 591.0,203.66666666666666 591.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M591.0,224.0 L595.0,216.0 587.0,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-5\" stroke-width=\"2px\" d=\"M722,222.0 722,185.33333333333334 924.0,185.33333333333334 924.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M722,224.0 L718,216.0 726,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-6\" stroke-width=\"2px\" d=\"M832,222.0 832,203.66666666666666 921.0,203.66666666666666 921.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M832,224.0 L828,216.0 836,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-7\" stroke-width=\"2px\" d=\"M612,222.0 612,167.0 927.0,167.0 927.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M927.0,224.0 L931.0,216.0 923.0,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-8\" stroke-width=\"2px\" d=\"M942,222.0 942,203.66666666666666 1031.0,203.66666666666666 1031.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1031.0,224.0 L1035.0,216.0 1027.0,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-342d4aa2e83b46ca9796762d412d1888-0-9\" stroke-width=\"2px\" d=\"M612,222.0 612,148.66666666666669 1150.0,148.66666666666669 1150.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-342d4aa2e83b46ca9796762d412d1888-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150.0,224.0 L1154.0,216.0 1146.0,216.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep', jupyter=True, options={'distance':110,\n",
    "               'compact':True, 'color':'Yellow', 'bg':'red', 'font':'times'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09169625-8f1b-4321-9184-a0661349d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\anaconda3\\Lib\\site-packages\\spacy\\displacy\\__init__.py:106: UserWarning: [W011] It looks like you're calling displacy.serve from within a Jupyter notebook or a similar environment. This likely means you're already running a local web server, so there's no need to make displaCy start another one. Instead, you should be able to replace displacy.serve with displacy.render to show the visualization.\n",
      "  warnings.warn(Warnings.W011)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"cfd4117a6e844610877f00d5480c7f5d-0\" class=\"displacy\" width=\"1260\" height=\"357.0\" direction=\"ltr\" style=\"max-width: none; height: 357.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">quick</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">brown</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">fox</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">jumped</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">overt</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">lazy</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">dog</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">'s</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"267.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">back</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-0\" stroke-width=\"2px\" d=\"M70,222.0 C70,57.0 375.0,57.0 375.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,224.0 L62,212.0 78,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-1\" stroke-width=\"2px\" d=\"M180,222.0 C180,112.0 370.0,112.0 370.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M180,224.0 L172,212.0 188,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-2\" stroke-width=\"2px\" d=\"M290,222.0 C290,167.0 365.0,167.0 365.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,224.0 L282,212.0 298,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-3\" stroke-width=\"2px\" d=\"M400,222.0 C400,167.0 475.0,167.0 475.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,224.0 L392,212.0 408,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-4\" stroke-width=\"2px\" d=\"M510,222.0 C510,167.0 585.0,167.0 585.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M585.0,224.0 L593.0,212.0 577.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-5\" stroke-width=\"2px\" d=\"M730,222.0 C730,112.0 920.0,112.0 920.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,224.0 L722,212.0 738,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-6\" stroke-width=\"2px\" d=\"M840,222.0 C840,167.0 915.0,167.0 915.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,224.0 L832,212.0 848,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-7\" stroke-width=\"2px\" d=\"M620,222.0 C620,57.0 925.0,57.0 925.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,224.0 L933.0,212.0 917.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-8\" stroke-width=\"2px\" d=\"M950,222.0 C950,167.0 1025.0,167.0 1025.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1025.0,224.0 L1033.0,212.0 1017.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-cfd4117a6e844610877f00d5480c7f5d-0-9\" stroke-width=\"2px\" d=\"M620,222.0 C620,2.0 1150.0,2.0 1150.0,222.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-cfd4117a6e844610877f00d5480c7f5d-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150.0,224.0 L1158.0,212.0 1142.0,212.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Oct/2024 03:36:58] \"GET / HTTP/1.1\" 200 9194\n",
      "127.0.0.1 - - [16/Oct/2024 03:36:58] \"GET /favicon.ico HTTP/1.1\" 200 9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down server on port 5000.\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(doc, style='dep', options={'distance':110})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af0ddca7-d67c-44db-92de-0ed5eeac5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 127.0.0.1:5000 -> type this on "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "241685e9-e191-4611-99bc-8e58a33ef651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy.render -> for single line\n",
    "# spacy.serve -> for multiple lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5dae3-eb0f-408e-9048-3eb2b30eb646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displacy.serve() accepts a single Doc or list of Doc objects. Since large\n",
    "# texts are difficult to view in one line, you may want to pass a list of \n",
    "# spans instead. Each span will apear on its own line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "018f6a6a-cd40-46b1-9ee2-cbc75dda80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"This is a sentence. This is another, possibly longer sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ad7a800-5d7f-4823-a4e4-9e8b99e629ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spans from Doc.sents:\n",
    "spans = list(doc2.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a48799-7d38-445b-a338-2fc4254e711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c9c1b2e0fb734da3be09062f5a37a68d-0\" class=\"displacy\" width=\"490\" height=\"247.0\" direction=\"ltr\" style=\"max-width: none; height: 247.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"157.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-0-0\" stroke-width=\"2px\" d=\"M70,112.0 C70,57.0 155.0,57.0 155.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,114.0 L62,102.0 78,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-0-1\" stroke-width=\"2px\" d=\"M290,112.0 C290,57.0 375.0,57.0 375.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,114.0 L282,102.0 298,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-0-2\" stroke-width=\"2px\" d=\"M180,112.0 C180,2.0 380.0,2.0 380.0,112.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M380.0,114.0 L388.0,102.0 372.0,102.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c9c1b2e0fb734da3be09062f5a37a68d-1\" class=\"displacy\" width=\"710\" height=\"302.0\" direction=\"ltr\" style=\"max-width: none; height: 302.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">another,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">possibly</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">longer</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"212.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-0\" stroke-width=\"2px\" d=\"M70,167.0 C70,112.0 150.0,112.0 150.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,169.0 L62,157.0 78,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-1\" stroke-width=\"2px\" d=\"M290,167.0 C290,57.0 595.0,57.0 595.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M290,169.0 L282,157.0 298,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-2\" stroke-width=\"2px\" d=\"M400,167.0 C400,112.0 480.0,112.0 480.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,169.0 L392,157.0 408,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-3\" stroke-width=\"2px\" d=\"M510,167.0 C510,112.0 590.0,112.0 590.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M510,169.0 L502,157.0 518,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-4\" stroke-width=\"2px\" d=\"M180,167.0 C180,2.0 600.0,2.0 600.0,167.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c9c1b2e0fb734da3be09062f5a37a68d-1-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M600.0,169.0 L608.0,157.0 592.0,157.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using the 'dep' visualizer\n",
      "Serving on http://0.0.0.0:5000 ...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [16/Oct/2024 03:45:28] \"GET / HTTP/1.1\" 200 8131\n",
      "127.0.0.1 - - [16/Oct/2024 03:45:28] \"GET /favicon.ico HTTP/1.1\" 200 8131\n"
     ]
    }
   ],
   "source": [
    "displacy.serve(spans, style='dep', options={'distance': 110})\n",
    "\n",
    "# //yha pe cell stop krne ke liye. kernal ke niche stop ka symbol hoga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561606ac-4392-41d9-8967-ba0fec7f392b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click this link to view the dependency: https://127.0.0.1:5000\n",
    "# Interrupt the kernel to return to jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a288edd-fea6-4db7-9331-2e5211261488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b25560b2-e188-4797-93e5-7f5770710bf7",
   "metadata": {},
   "source": [
    "# NER (Named Entity Regonition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4a941f7-4d05-4ffa-a23e-8c877d3e0c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0abf1386-b28d-43ce-b9d4-fbaa9a2c07a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to display basic entity info:\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e26c042-12c0-49e8-97ed-5be76cb90478",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0d72ba1-f422-451f-afba-4c7e2a608954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Washington, DC - GPE - Countries, cities, states\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07ec9598-fd82-4426-996c-18ed76be8b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Can I please borrow 500 dollars from you to buy some Microsoft stock?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e94d9ec6-8cea-4613-9dfd-31e6bb28d8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 dollars 4 6 20 31 MONEY\n",
      "Microsoft 11 12 53 62 ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start, ent.end, ent.start_char, ent.end_char, ent.label_)\n",
    "\n",
    "# Explanation\n",
    "#<-------------->\n",
    "# 500 dollars 4 6 20 31 MONEY -> 4 is starting index of tokens.\n",
    "# tokens index also start from 0.\n",
    "\n",
    "# 20 is the character index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "862206fc-edf1-42b5-978f-712426efe7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Tesla is build to U.K factory for $6 million.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eb94dfc-4d05-4a8f-bf98-52c8ea9dc47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla - ORG - Companies, agencies, institutions, etc.\n",
      "U.K - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbac8ad9-f529-425d-8d82-411dd6961280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18229421-dc71-493a-85d1-76d35c9344b0",
   "metadata": {},
   "source": [
    "# Adding tokens in spacy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6b03059-5286-4c39-88fd-6514b127b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Right now, spaCy does not recognize \"Tesla\" as a company.\n",
    "\n",
    "# Note: kisi kisi ke laptop me tesla added word ni hai to niche wala code add krne ke liye hai.\n",
    "# but mere laptop me add hai to niche wale code se error ayega."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "307e572d-d9f5-4f72-a6db-6c0a52396a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efacf568-56a4-4586-baec-ddff45ae24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the hash value of the ORG entity label\n",
    "ORG = doc.vocab.strings[u'ORG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64de01ce-b77a-4d9f-8a65-4b732cf168ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crreate a Span for the new entitiy\n",
    "new_ent = Span(doc, 0,1, label=ORG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "971fb95e-68c3-43a2-8e7d-f0b06f364ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the entitty to the existing Doc object \n",
    "# doc.ents = list(doc.ents) + [new_ent]\n",
    "\n",
    "# /it shows error because tesla word is exist in my entity dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60afd74f-b8bc-4a5f-9a52-f083f28ea7c9",
   "metadata": {},
   "source": [
    "# to do some code error oct 17 take from swarnim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1bde7-d91d-4ea5-9efa-9807c2c6191d",
   "metadata": {},
   "source": [
    "# oct 17 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efcfd7-47d6-416b-bbee-237d6bc8056e",
   "metadata": {},
   "source": [
    "# Adding Named Entities to All Matching Spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07bef5e6-aaa9-448f-af56-24b3e0add84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What isf we want to tag all occurences of \"Tesla\"? In this section we \n",
    "# show how to use the PhraseMatcher to identity a series of spans in the\n",
    "# Doc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3aefb0a-097a-4660-990e-0502080d9fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Our company plans to introduce a new vaccum cleaner. '\n",
    "          u'If successful, the vaccum cleaner will be our first product.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9de5333-7b22-4799-bae9-beda6a258d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents2:\n",
    "            print(ent.text, ent.label_)\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18ec87e-760c-41ab-b8cb-810825e3f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first ORDINAL\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b19b7dbb-e74b-46cd-85a1-c4ca4692656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PhraseMatcher and create a matcher object:\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed5396db-307e-4833-b50b-031c92ea98ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the desired phrase patterns:\n",
    "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "304e93f8-f69b-460f-94b5-7dc4503ce735",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('newproduct', None, *phrase_patterns)\n",
    "matchers = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a953d099-de3c-4521-ad20-43ec135bb65c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matches' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Span\n\u001b[0;32m      4\u001b[0m PROD \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mstrings[\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPRODUCT\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 5\u001b[0m new_ents \u001b[38;5;241m=\u001b[39m [Span(doc, match[\u001b[38;5;241m1\u001b[39m], match[\u001b[38;5;241m2\u001b[39m], label\u001b[38;5;241m=\u001b[39mPROD) \u001b[38;5;28;01mfor\u001b[39;00m match \u001b[38;5;129;01min\u001b[39;00m matches]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matches' is not defined"
     ]
    }
   ],
   "source": [
    "# Here we create Spans from each match, and create named entities from them:\n",
    "\n",
    "from spacy.tokens import Span\n",
    "PROD = doc.vocab.strings[u'PRODUCT']\n",
    "new_ents = [Span(doc, match[1], match[2], label=PROD) for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53c8a846-14b8-485d-a799-b26e4d11bf89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_ents' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# doc.ents = list(doc.ents) + new_ents\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m doc\u001b[38;5;241m.\u001b[39ments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(doc\u001b[38;5;241m.\u001b[39ments) \u001b[38;5;241m+\u001b[39m new_ents\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_ents' is not defined"
     ]
    }
   ],
   "source": [
    "# doc.ents = list(doc.ents) + new_ents\n",
    "\n",
    "doc.ents = list(doc.ents) + new_ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "784f13cf-5a94-4567-8d9f-99844ffa7233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first ORDINAL\n"
     ]
    }
   ],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21929dd1-2d89-40aa-b676-16824da88f4f",
   "metadata": {},
   "source": [
    "# Counting Entites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9539575-255f-4ca6-a945-a320e88d9bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 MONEY\n",
      "five dollars MONEY\n"
     ]
    }
   ],
   "source": [
    "# While spaCy may not have a built-in tools for counting entites, we can pass a conditional statement into a list comprehension:\n",
    "doc = nlp(u'Originally prices at $29.50, the sweater was marked down to five dollars.')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1ee8e2c-92e6-4d6d-8b84-3033ebd5d569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label_ == 'MONEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e50f36d-4c3a-4df6-a993-82b5b4723839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50 MONEY\n",
      "five dollars MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Originally prices at $29.50, \\n sweater was marked down to five dollars.')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5240064-c7bd-420c-8936-2eca7db48986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label_ == 'MONEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "632fb45a-db4b-4db9-a495-4cdf2925ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Autonoums cars shift insurance liability toward manufactures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "157884b2-2dbe-4827-a22e-17e861d5113b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonoums cars - cars - nsubj - shift\n",
      "insurance liability - liability - dobj - shift\n",
      "manufactures - manufactures - pobj - toward\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text+' - '+chunk.root.text+' - '+chunk.root.dep_+' - '+chunk.root.head.text)\n",
    "\n",
    "# //Here 3 noun chunks\n",
    "# -> words describing the nouns is called noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0702d7e2-7439-48a2-817c-7cdf595e029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Doc.noun_chunks is a generator function\n",
    "#<-------------------------------------------------->\n",
    "\n",
    "# Previously we mentioned that Doc objects objects do not retain a list of \n",
    "# sentences, but they're available through the Doc.sents generator. \n",
    "# It's the same with Doc.noun_chunks - lists can be created "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2744f-0f5c-4ae0-b349-003f0ba9fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Visualize Named Entites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b132a542-d58d-4c70-9f97-363fd996f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3389629-6f46-4100-9906-082dcdd4e0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".By contrast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sony\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only 7 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " Walkman music players.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(u\"Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.\" \n",
    "            u\"By contrast, Sony sold only 7 thousand Walkman music players.\")\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58d4fa-7c18-482b-8cb0-b122955620a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab2ceb63-5269-4276-8fd2-fcfea4766425",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d47212e-f04e-442d-b8f9-dce32fdec1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform standard imports\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d937ee81-08eb-4f63-9b12-31d1eb183f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39b717da-9be2-4880-acfc-8ce3fc0a19d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40aabfb8-d637-4d25-967b-37fca6bb3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######## Doc.sents is a generator\n",
    "#<------------------------------------>\n",
    "\n",
    "# # It is important to note that doc.sents is a genrator. This \n",
    "# is, a Doc is not segmented until doc.sents is called. This means that, where you \n",
    "# could print the second Doc token with print(doc[1]), you can't call \n",
    "# the \"second Doc sentence\" with print(doc.sents[1]):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68d59fe1-b3ef-495f-9e33-babfc13146d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n"
     ]
    }
   ],
   "source": [
    "print(doc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "edb60302-3842-4147-846e-083ba8663351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(doc.sents[1])\n",
    "# //error becoz sentence can not be access without loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd35abb5-f229-4acc-848d-e276649a4be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the first sentence.,\n",
       " This is another sentence.,\n",
       " This is the last sentence.]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents = [sent for sent in doc.sents]\n",
    "doc_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f16ba9-6e6e-4f50-b5bc-02b4f11be281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: list(doc.sents) also works. We show a list comprehension as it \n",
    "# allows you to pass in conditionals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8876dc5b-0e54-4de6-a099-4dbd19fc9924",
   "metadata": {},
   "source": [
    "# to do some codes missing below 18 oct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca6c27-7e58-47d7-a550-c05d19ff7e74",
   "metadata": {},
   "source": [
    "# 18 oct 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500bc6a-a1da-47db-a764-6eb3ac1be0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP_Part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50a72259-a4a0-47a8-a024-2346735f3a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba7bdc9-ba3e-45f1-aa42-d6e99a25918c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u'This is a sentence. This is a sentence. This is a sentence')\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.is_sent_start, ' '+token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79631939-ee2b-438c-9f2a-6a7fd8aba0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a21048db-b4b7-4dc2-b4b5-5e102b74e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence.\n",
      "This is a sentence.\n",
      "This is a sentence\n"
     ]
    }
   ],
   "source": [
    "for doc2 in doc2.sents:\n",
    "    print(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0dbc5189-83a6-4eaf-b256-c1e1fa5e2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spact Default Behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16adbd8d-8f26-4972-9204-f479a930cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" ~Peter Drucker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe8e8f62-d879-4bf9-a4d0-d2fd55c8cead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "~Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ad018b0-3c26-49c3-87fe-31242efb773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new rule to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d806e0c7-f37e-400f-a2c2-f7c2c56c33ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1696870582.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[53], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    token.text==';':\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        token.text==';':\n",
    "            doc[token.i+1].is_sent_start=True\n",
    "                return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02a958d-262a-41e3-ae82-9641805caca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e44d541b-4928-4e21-b7bb-3cdac66803f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d24a2a07-87a1-4ee3-bdf5-77d53ce9c3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Acer\\Downloads\\IMDB Dataset.xls\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90230513-6f37-476c-87a6-a9743ce86cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec6c1b20-5aea-47e9-b550-03d79007ad40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5f3394b2-b0d7-49bb-909b-97ba79faf052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      one of the other reviewers has mentioned that ...  positive\n",
       "1      a wonderful little production. <br /><br />the...  positive\n",
       "2      i thought this was a wonderful way to spend ti...  positive\n",
       "3      basically there's a family where a little boy ...  negative\n",
       "4      petter mattei's \"love in the time of money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  i thought this movie did a down right good job...  positive\n",
       "49996  bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  i am a catholic taught in parochial elementary...  negative\n",
       "49998  i'm going to have to disagree with the previou...  negative\n",
       "49999  no one expects the star trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lower the dataset text\n",
    "#<------------------------->im\n",
    "\n",
    "df['review'] = df['review'].str.lower()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e94147c-2b10-4ad8-8c7c-bf296eed07f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('text')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "586d22f9-647b-4f61-bd89-846fd774eb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5f43e7a0-524b-4660-8c80-6a3c3c13a03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_tags(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d1bb0b2e-6f88-4c55-ae78-77db72d08488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punctuation\n",
    "#<--------------->\n",
    "\n",
    "from string import punctuation\n",
    "a = punctuation\n",
    "len(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f42c83-fbee-468d-b76b-a4103e0faed9",
   "metadata": {},
   "source": [
    "# 3. Remove URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1f5ace6f-6e94-4311-be48-e1d71451967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www.\\/\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ae6d7d84-2641-4080-9dee-eeb6206d85ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = 'check out my notebook https://www.kaggle.com/code'\n",
    "text2 = 'Google search here https://www.google.com/'\n",
    "text3 = 'for notebook click https://www/kaggle.com/code to search check https://www.google.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "409f4849-f01b-42a8-9b04-71d625c0b38c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'check out my notebook '"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_url(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6dc99-8ebb-41c1-b4af-ccde9d34a4f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e40e47c8-d8f2-423a-9324-c8931b4e4734",
   "metadata": {},
   "source": [
    "# TO DO some codes missing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3694aec8-9d13-4c88-85fd-40a7b8d13240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jha pe upar error hai use resolve krna hai. 2 days error 17 oct, 18 oct,\n",
    "# and to do by swarnim 3rd error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18c6bad-7aea-4e3a-8c70-e8537c6bb9e9",
   "metadata": {},
   "source": [
    "# 4:Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4800cf51-d707-4bcb-a7cd-66cd42ee7b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d1f42cc8-244a-484d-8277-df9794d634ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# mycode\n",
    "a = string.punctuation\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33e907fa-8b4d-4885-86e0-b57578dd8350",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e109d00f-64fa-4f54-9b1d-9db924b56168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3209771c-d7d8-4c07-967e-5eaaf49664ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'strings& with\\\\ Punctuation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfc46901-839d-4f18-87f2-557c22e33954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strings with Punctuation\n"
     ]
    }
   ],
   "source": [
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd9f9f75-406e-4781-aa00-b114eb7033f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97e8372e-5846-4ba6-a3a1-9299bd014232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abbreviation -> short form\n",
    "# like pfa -> please find attachement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "479df4ce-446e-4f02-bc66-70ea43fea436",
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = [\n",
    "    (\"AFAIK\",\"As Far As I know\"),\n",
    "    (\"AFK\",\"Away From Keyboard\"),\n",
    "    (\"ASAP\",\"As Soon As Possible\"),\n",
    "    (\"ATK\",\"At The Keyboard\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3746aa0-81ab-450e-9e10-773b719115d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AFAIK': 'As Far As I know', 'AFK': 'Away From Keyboard', 'ASAP': 'As Soon As Possible', 'ATK': 'At The Keyboard'}\n"
     ]
    }
   ],
   "source": [
    "abbreviations_dict = {abbr: meaning for abbr, meaning in abbreviations}\n",
    "print(abbreviations_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17249c43-7498-4e90-ac6e-342246f1653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in abbreviations_dict:\n",
    "            new_text.append(abbreviations_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85134b7b-0e6a-41b3-a5b9-97a97a88d55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATX'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('ATX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9b87c09-fcc9-482a-84d4-439ad609ee7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PFA'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('PFA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7515b7a7-2284-4257-8476-545086655956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATX\n"
     ]
    }
   ],
   "source": [
    "a = 'ATX'\n",
    "for i in a.split():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3545a7e4-e5ac-46b8-8903-ea3cc51c46d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please submit report As Soon As Possible'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_conversion('please submit report asap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03b19b9-a86a-4ac6-ae1f-49fc86684e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e299a80b-3fe8-4031-bfe0-7bc4d11a7a94",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bf735fa-233c-4c51-95dc-bb99fe95b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5951cca1-e6d4-43b0-a4b3-c5330ca985e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "228d2ded-be37-4847-b4f4-796c78bee807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopword = stopwords.words('english')\n",
    "# print(stopword)\n",
    "\n",
    "stop = stopwords.words(\"english\")\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d45d05ac-be02-45ce-b717-939f1b8cf5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "en = stopwords.words(\"english\")\n",
    "sp = stopwords.words(\"spanish\")\n",
    "print(len(en))\n",
    "print(len(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e83fb138-c5da-4892-be83-e538afe1fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "313\n"
     ]
    }
   ],
   "source": [
    "en = stopwords.words(\"english\")\n",
    "sp = stopwords.words(\"spanish\")\n",
    "print(len(en))\n",
    "print(len(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b75f7-26b7-4223-9c16-6e82661bafa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84320a2b-543e-4364-99bb-7d1464781cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372d64e-ccb1-496b-8b68-549228d87fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf92ab8f-a73f-4ce3-b90b-ea1bd8e964e2",
   "metadata": {},
   "source": [
    "# Emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f64d14-7c59-4a8d-b2b0-b38b1a3ebb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4af2ed77-3e7a-4cef-94a0-4178f7e53953",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01memoji\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(emoji\u001b[38;5;241m.\u001b[39mdemojize(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mI hate python 😊\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize('I hate python 😊'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e2d3f-64cb-4849-9dec-20960956a3dd",
   "metadata": {},
   "source": [
    "# 1. Using split Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0595c64-9a17-4d10-8a6b-b2d1ab1ab8dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word tokenization\n",
    "sent1 = 'I am going to delhi'\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "790f0f43-6a9f-4ecd-9a58-dfef84e5bd6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I am going to delhi. I will stay there for 3 days. Let's hope the trip to be great\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = 'I am going to delhi. I will stay there for 3 days. Let\\'s hope the trip to be great'\n",
    "sent2.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20a206e9-26f3-4928-88be-91148a06499e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi!.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problems with split function\n",
    "sent3 = 'I am going to delhi!.'\n",
    "sent3.split()\n",
    "\n",
    "# here problem to split\n",
    "# it does not split punctuation ! and full stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66458e21-b7ec-4ddf-aced-de1f3eb7d837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['where do think I should go? I have 3 day holiday']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent4 = 'where do think I should go? I have 3 day holiday'\n",
    "sent4.split('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2973308a-3460-41e8-921c-2e265a693740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent3 = 'I am going to delhi!.'\n",
    "tokens = re.findall(\"[\\w]+\",sent3)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fa580069-291b-424e-8646-c050ee87f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Lorem ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipusum has been the industry's standard dummy text evere since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\"\n",
    "sentence = re.compile('[.!?]').split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26fe600c-82bc-4453-a064-b23052e60889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lorem ipsum is simply dummy text of the printing and typesetting industry',\n",
       " \"\\nLorem Ipusum has been the industry's standard dummy text evere since the 1500s,\\nwhen an unknown printer took a galley of type and scrambled it to make a type specimen book\",\n",
       " '']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f0325f-a31f-4a14-b143-331cdb627691",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2721de7-d481-460c-a6ad-76d80264c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbb02268-73ae-4ea9-b265-d6b96bc4621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punck: Package 'punck' not found in index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punck')\n",
    "\n",
    "# if look up error then run this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04385d1b-d430-415d-bcee-133cf266e357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi', '!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = 'I am going to delhi!'\n",
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3a68c5-5bbc-4be3-94d0-5dc3c8754ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Lorem ipsum is simply dummy text of the printing and typesetting industry?\n",
    "Lorem Ipusum has been the industry's standard dummy text evere since the 1500s,\n",
    "when an unknown printer took a galley of type and scrambled it to make a type specimen book.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2639544-3704-4e60-9717-f4929d0352df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent5 = 'I have a Ph.D in A.I'\n",
    "sent6 = \"We're here to help! mail us at abc@gmail.com\"\n",
    "sent7 = 'A 5km ride cost $10.50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1686ed34-b6dc-498d-b2d2-6f72c58df61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'Ph.D', 'in', 'A.I']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "074c9ad3-7de6-4a84-8d41-51a66f48f532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We',\n",
       " \"'re\",\n",
       " 'here',\n",
       " 'to',\n",
       " 'help',\n",
       " '!',\n",
       " 'mail',\n",
       " 'us',\n",
       " 'at',\n",
       " 'abc',\n",
       " '@',\n",
       " 'gmail.com']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77a468eb-d061-447f-94fc-4a94a9300afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['We', \"'re\", 'here', 'to', 'help', '!', 'mail', 'us', 'at', 'abc', '@', 'gmail.com']"
     ]
    }
   ],
   "source": [
    "# my code hroizontally print\n",
    "a = word_tokenize(sent6)\n",
    "print(a,end= '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f5cbc5-45a5-4d6e-8a98-d3d5955532e2",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd139f6a-49a4-43aa-87b8-96e8dd651c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a20a97ea-669f-4ec6-a567-c1886b629a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d05e76bf-379c-4852-9b6f-ec2e34bf9614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = \"walk walks walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ceab5708-40f0-4e2f-b598-d3db924ac474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Acer\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# bcoz look error in below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25228f87-48c6-4ee1-9d0d-d060f41ea3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "He                  He                  \n",
      "was                 wa                  \n",
      "running             running             \n",
      "and                 and                 \n",
      "eating              eating              \n",
      "at                  at                  \n",
      "the                 the                 \n",
      "same                same                \n",
      "time                time                \n",
      "He                  He                  \n",
      "has                 ha                  \n",
      "bad                 bad                 \n",
      "habit               habit               \n",
      "of                  of                  \n",
      "swimming            swimming            \n",
      "after               after               \n",
      "playing             playing             \n",
      "long                long                \n",
      "hours               hour                \n",
      "in                  in                  \n",
      "the                 the                 \n",
      "sun                 sun                 \n"
     ]
    }
   ],
   "source": [
    "# //get lemmatizer word using nltk\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at the same time. He has bad habit of swimming after playing long hours in the sun.\"\n",
    "punctuations=\"?:!.,;*\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f588a1d-27d9-4b2f-ad12-c2d42735d12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab39fcd-492d-490e-bc46-334c2e5d2596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a542a-b6b3-4777-a011-9deed05d3a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887aeac7-099a-4c9d-b4b1-9ac6c6b93a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6166209d-5861-4f4d-aab9-4c0c97a87922",
   "metadata": {},
   "source": [
    "# 7-11-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba846ea0-5c52-4f61-87d8-684fb26f41df",
   "metadata": {},
   "source": [
    "## Text vectorizer (text to numbers) and bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3216b0b1-d10b-41de-a17b-84ce78435bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63da746-8860-415b-bcfb-4638125ace4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'text':['people watch campus', 'campus watch campus','people write comment','campus write comment'],'output':[1,1,0,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2aa5fbb-23ea-45a3-abc4-4061d289af27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>people watch campus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campus watch campus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>people write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campus write comment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text  output\n",
       "0   people watch campus       1\n",
       "1   campus watch campus       1\n",
       "2  people write comment       0\n",
       "3  campus write comment       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20c60626-8112-4d0e-b22a-9714b05b91a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a307ea38-34d3-43d3-8236-d46ffcd41d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': 2, 'watch': 3, 'campus': 0, 'write': 4, 'comment': 1}\n"
     ]
    }
   ],
   "source": [
    "# vocab\n",
    "print(cv.vocabulary_)\n",
    "\n",
    "# vocabulary means -> unique words\n",
    "\n",
    "# {'people': 2, 'watch': 3, 'campus': 0, 'write': 4, 'comment': 1}\n",
    "# number is assign alphabetically\n",
    "\n",
    "# campus, comment, peopel, watch, write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5513d32-c683-4554-b515-addb53ff241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "bow = cv.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e7eb7c3-95fb-4e96-aab4-f238dafed643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 1 0]]\n",
      "[[2 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(bow[0].toarray())\n",
    "print(bow[1].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca61ce9-430f-47e9-9de6-dee164ca3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.transform([\"campus watch and write comment of campus\"]).toarray()\n",
    "\n",
    "# NOTE: IN COUNT VECTORIZER HMNE \"and\", \"of\" is new word.\n",
    "# to ise count vectorizer, ohe, bog tine me se koi identify ni kr pa rha hai."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db13a6cb",
   "metadata": {},
   "source": [
    "# 28nov2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef99699",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a144b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49681612, 0.        , 0.61366674, 0.61366674, 0.        ],\n",
       "       [0.8508161 , 0.        , 0.        , 0.52546357, 0.        ],\n",
       "       [0.        , 0.57735027, 0.57735027, 0.        , 0.57735027],\n",
       "       [0.49681612, 0.61366674, 0.        , 0.        , 0.61366674]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit_transform(df['text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f2146f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.22314355 1.51082562 1.51082562 1.51082562 1.51082562]\n",
      "['campus' 'comment' 'people' 'watch' 'write']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.idf_)\n",
    "print(tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa79b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae72e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67359d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
